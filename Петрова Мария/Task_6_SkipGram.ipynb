{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Text8 Dataset: 31.4MB [02:33, 204kB/s]                                         \n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "\n",
    "dataset_folder_path = 'data'\n",
    "dataset_filename = 'text8.zip'\n",
    "dataset_name = 'Text8 Dataset'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(dataset_filename):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc=dataset_name) as pbar:\n",
    "        urlretrieve(\n",
    "            'http://mattmahoney.net/dc/text8.zip',\n",
    "            dataset_filename,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(dataset_folder_path):\n",
    "    with zipfile.ZipFile(dataset_filename) as zip_ref:\n",
    "        zip_ref.extractall(dataset_folder_path)\n",
    "        \n",
    "with open('data/text8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including', 'the', 'diggers', 'of', 'the', 'english', 'revolution', 'and', 'the', 'sans', 'culottes', 'of', 'the', 'french', 'revolution', 'whilst']\n"
     ]
    }
   ],
   "source": [
    "words = utils.preprocess(text)\n",
    "print(words[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 16680599\n",
      "Unique words: 63641\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words: {}\".format(len(words)))\n",
    "print(\"Unique words: {}\".format(len(set(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_to_int, int_to_vocab = utils.create_lookup_tables(words)\n",
    "int_words = [vocab_to_int[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "threshold = 1e-5\n",
    "word_counts = Counter(int_words)\n",
    "total_count = len(int_words)\n",
    "freqs = {word: count/total_count for word, count in word_counts.items()}\n",
    "p_drop = {word: 1 - np.sqrt(threshold/freqs[word]) for word in word_counts}\n",
    "train_words = [word for word in int_words if random.random() < (1 - p_drop[word])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target(words, idx, window_size=5):\n",
    "    ''' Get a list of words in a window around an index. '''\n",
    "    \n",
    "    R = np.random.randint(1, window_size+1)\n",
    "    start = idx - R if (idx - R) > 0 else 0\n",
    "    stop = idx + R\n",
    "    target_words = set(words[start:idx] + words[idx+1:stop+1])\n",
    "    \n",
    "    return list(target_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(words, batch_size, window_size=5):\n",
    "    ''' Create a generator of word batches as a tuple (inputs, targets) '''\n",
    "    \n",
    "    n_batches = len(words)//batch_size\n",
    "    \n",
    "    # only full batches\n",
    "    words = words[:n_batches*batch_size]\n",
    "    \n",
    "    for idx in range(0, len(words), batch_size):\n",
    "        x, y = [], []\n",
    "        batch = words[idx:idx+batch_size]\n",
    "        for ii in range(len(batch)):\n",
    "            batch_x = batch[ii]\n",
    "            batch_y = get_target(batch, ii, window_size)\n",
    "            y.extend(batch_y)\n",
    "            x.extend([batch_x]*len(batch_y))\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    inputs = tf.placeholder(tf.int32, [None], name='inputs')\n",
    "    labels = tf.placeholder(tf.int32, [None, None], name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_vocab = len(int_to_vocab)\n",
    "n_embedding = 200 # Number of embedding features \n",
    "with train_graph.as_default():\n",
    "    embedding = tf.Variable(tf.random_uniform((n_vocab, n_embedding), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:1346: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_sampled = 100\n",
    "with train_graph.as_default():\n",
    "    softmax_w = tf.Variable(tf.truncated_normal((n_vocab, n_embedding), stddev=0.1))\n",
    "    softmax_b = tf.Variable(tf.zeros(n_vocab))\n",
    "    \n",
    "    # Calculate the loss using negative sampling\n",
    "    loss = tf.nn.sampled_softmax_loss(softmax_w, softmax_b, \n",
    "                                      labels, embed,\n",
    "                                      n_sampled, n_vocab)\n",
    "    \n",
    "    cost = tf.reduce_mean(loss)\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-0edb403d10d5>:13: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "with train_graph.as_default():\n",
    "    ## From Thushan Ganegedara's implementation\n",
    "    valid_size = 16 # Random set of words to evaluate similarity on.\n",
    "    valid_window = 100\n",
    "    # pick 8 samples from (0,100) and (1000,1100) each ranges. lower id implies more frequent \n",
    "    valid_examples = np.array(random.sample(range(valid_window), valid_size//2))\n",
    "    valid_examples = np.append(valid_examples, \n",
    "                               random.sample(range(1000,1000+valid_window), valid_size//2))\n",
    "\n",
    "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "    \n",
    "    # We use the cosine distance:\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embedding), 1, keep_dims=True))\n",
    "    normalized_embedding = embedding / norm\n",
    "    valid_embedding = tf.nn.embedding_lookup(normalized_embedding, valid_dataset)\n",
    "    similarity = tf.matmul(valid_embedding, tf.transpose(normalized_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 Iteration: 100 Avg. Training loss: 5.6609 2.0420 sec/batch\n",
      "Epoch 1/10 Iteration: 200 Avg. Training loss: 5.6205 1.9677 sec/batch\n",
      "Epoch 1/10 Iteration: 400 Avg. Training loss: 5.5830 1.9493 sec/batch\n",
      "Epoch 1/10 Iteration: 500 Avg. Training loss: 5.5011 1.9630 sec/batch\n",
      "Epoch 1/10 Iteration: 600 Avg. Training loss: 5.5541 1.9625 sec/batch\n",
      "Epoch 1/10 Iteration: 700 Avg. Training loss: 5.5555 1.9512 sec/batch\n",
      "Epoch 1/10 Iteration: 800 Avg. Training loss: 5.5697 1.9570 sec/batch\n",
      "Epoch 1/10 Iteration: 900 Avg. Training loss: 5.4876 1.9549 sec/batch\n",
      "Epoch 1/10 Iteration: 1000 Avg. Training loss: 5.4274 1.9394 sec/batch\n",
      "Nearest to it: laden, speculate, rhotic, bulges, chlorofluorocarbons, copyrights, smart, notably,\n",
      "Nearest to four: forcefully, wb, bat, kilowatts, lesbianism, musk, okinawa, carrel,\n",
      "Nearest to called: pug, supers, quebec, north, angiotensin, germaine, pashtunistan, unchanged,\n",
      "Nearest to th: scholarly, instrumentalists, cnd, primality, inspired, stipulation, synergistic, waxed,\n",
      "Nearest to years: infocom, rocker, wallace, harvest, recalcitrant, weasel, andreyev, gladiators,\n",
      "Nearest to were: garagiola, horton, alferd, speed, eec, library, cavalli, intermediate,\n",
      "Nearest to their: saloon, mugabe, deterioration, malted, zoo, metron, formative, fermionic,\n",
      "Nearest to other: vitro, cavers, babylonian, usually, sofa, ashes, nhu, rez,\n",
      "Nearest to file: pancreatitis, rivaled, assemblages, magdalene, nostra, bell, obtuse, strings,\n",
      "Nearest to construction: crawling, kimberley, remembrance, rashomon, southside, instep, bakr, overshadowed,\n",
      "Nearest to except: rafael, succesor, grimwood, encapsulation, kid, councilor, hauser, seiy,\n",
      "Nearest to shows: johannesburg, modules, vigen, dresden, manslaughter, integumentary, martial, sligo,\n",
      "Nearest to articles: basemen, gosh, tested, williams, miscible, manly, luk, tchaikovsky,\n",
      "Nearest to grand: firings, tirpitz, catatonia, leverage, teslas, brodie, bride, parishioners,\n",
      "Nearest to units: asimo, ayawaska, lengths, karol, watt, endpoint, ineffective, xenocrates,\n",
      "Nearest to resources: rewrote, fiercest, posteriori, supplies, dai, quorum, according, firenze,\n",
      "Epoch 1/10 Iteration: 1100 Avg. Training loss: 5.4870 1.9906 sec/batch\n",
      "Epoch 1/10 Iteration: 1200 Avg. Training loss: 5.3611 1.9570 sec/batch\n",
      "Epoch 1/10 Iteration: 1300 Avg. Training loss: 5.3154 1.9367 sec/batch\n",
      "Epoch 1/10 Iteration: 1400 Avg. Training loss: 5.2873 1.9360 sec/batch\n",
      "Epoch 1/10 Iteration: 1500 Avg. Training loss: 5.2205 1.9469 sec/batch\n",
      "Epoch 1/10 Iteration: 1600 Avg. Training loss: 5.1734 1.9378 sec/batch\n",
      "Epoch 1/10 Iteration: 1700 Avg. Training loss: 5.1276 1.9516 sec/batch\n",
      "Epoch 1/10 Iteration: 1800 Avg. Training loss: 5.0800 1.9486 sec/batch\n",
      "Epoch 1/10 Iteration: 1900 Avg. Training loss: 5.0172 1.9374 sec/batch\n",
      "Epoch 1/10 Iteration: 2000 Avg. Training loss: 4.9970 1.9581 sec/batch\n",
      "Nearest to it: notably, growing, speculate, laden, rhotic, seemed, smart, consultation,\n",
      "Nearest to four: forcefully, bat, wb, follow, superboy, kilowatts, lesbianism, cell,\n",
      "Nearest to called: north, help, isolation, take, quebec, unchanged, reunited, patient,\n",
      "Nearest to th: scholarly, raised, under, inspired, instrumentalists, elsewhere, cnd, stipulation,\n",
      "Nearest to years: harvest, infocom, exception, pennsylvania, gladiators, rocker, shared, successive,\n",
      "Nearest to were: speed, fifth, garagiola, horton, library, last, intermediate, broad,\n",
      "Nearest to their: saloon, deterioration, gradually, formative, zoo, mugabe, functioning, mode,\n",
      "Nearest to other: usually, cavers, ashes, conditions, vitro, september, babylonian, notably,\n",
      "Nearest to file: pancreatitis, rivaled, assemblages, magdalene, strings, comprising, editors, bell,\n",
      "Nearest to construction: crawling, remembrance, kimberley, instituted, southside, disappear, endow, disasters,\n",
      "Nearest to except: encapsulation, symptoms, kid, grimwood, introduces, succesor, mps, pieces,\n",
      "Nearest to shows: johannesburg, modules, dresden, manslaughter, vigen, enjoy, learned, integumentary,\n",
      "Nearest to articles: tested, williams, concept, holy, one, basemen, gosh, manly,\n",
      "Nearest to grand: firings, tirpitz, catatonia, bride, regulation, leverage, teslas, brodie,\n",
      "Nearest to units: lengths, growing, succeeded, watt, xenocrates, asimo, ayawaska, endpoint,\n",
      "Nearest to resources: according, rewrote, supplies, quorum, fiercest, price, patten, columns,\n",
      "Epoch 1/10 Iteration: 2100 Avg. Training loss: 4.9190 2.0160 sec/batch\n",
      "Epoch 1/10 Iteration: 2200 Avg. Training loss: 4.9333 1.9391 sec/batch\n",
      "Epoch 1/10 Iteration: 2300 Avg. Training loss: 4.9098 1.9504 sec/batch\n",
      "Epoch 1/10 Iteration: 2400 Avg. Training loss: 4.8719 1.9557 sec/batch\n",
      "Epoch 1/10 Iteration: 2500 Avg. Training loss: 4.8214 2.0273 sec/batch\n",
      "Epoch 1/10 Iteration: 2600 Avg. Training loss: 4.8332 1.9655 sec/batch\n",
      "Epoch 1/10 Iteration: 2700 Avg. Training loss: 4.8201 1.9342 sec/batch\n",
      "Epoch 1/10 Iteration: 2800 Avg. Training loss: 4.7945 1.9428 sec/batch\n",
      "Epoch 1/10 Iteration: 2900 Avg. Training loss: 4.7928 1.9492 sec/batch\n",
      "Epoch 1/10 Iteration: 3000 Avg. Training loss: 4.7789 1.9539 sec/batch\n",
      "Nearest to it: speculate, notably, laden, combinations, smart, growing, rhotic, consultation,\n",
      "Nearest to four: forcefully, wb, bat, harpercollins, rulings, kilowatts, rumours, ndel,\n",
      "Nearest to called: help, quebec, isolation, pug, supers, north, unchanged, take,\n",
      "Nearest to th: scholarly, raised, under, instrumentalists, stipulation, dionysius, elsewhere, cnd,\n",
      "Nearest to years: infocom, rocker, successive, harvest, wallace, weasel, pennsylvania, circulating,\n",
      "Nearest to were: garagiola, speed, horton, fifth, broad, hadrian, eec, last,\n",
      "Nearest to their: deterioration, saloon, formative, gradually, malted, zoo, probe, mugabe,\n",
      "Nearest to other: usually, cavers, vitro, syllabic, ashes, babylonian, upgrades, sofa,\n",
      "Nearest to file: pancreatitis, rivaled, editors, assemblages, strings, magdalene, ernie, bell,\n",
      "Nearest to construction: crawling, remembrance, instituted, kimberley, disappear, southside, protected, overshadowed,\n",
      "Nearest to except: encapsulation, pieces, rafael, introduces, kid, grimwood, mps, action,\n",
      "Nearest to shows: johannesburg, modules, martial, learned, dresden, manslaughter, enjoy, customer,\n",
      "Nearest to articles: williams, tested, gosh, expiration, delta, angles, manly, conclusive,\n",
      "Nearest to grand: catatonia, firings, bride, leverage, dyke, regulation, tirpitz, milestone,\n",
      "Nearest to units: lengths, watt, succeeded, gentle, alamogordo, asimo, ineffective, endpoint,\n",
      "Nearest to resources: rewrote, supplies, according, reasonably, fiercest, spiritualism, posteriori, eva,\n",
      "Epoch 1/10 Iteration: 3100 Avg. Training loss: 4.7805 1.9708 sec/batch\n",
      "Epoch 1/10 Iteration: 3200 Avg. Training loss: 4.7648 1.9539 sec/batch\n",
      "Epoch 1/10 Iteration: 3300 Avg. Training loss: 4.7199 1.9308 sec/batch\n",
      "Epoch 1/10 Iteration: 3400 Avg. Training loss: 4.7174 1.9392 sec/batch\n",
      "Epoch 1/10 Iteration: 3500 Avg. Training loss: 4.7350 1.9630 sec/batch\n",
      "Epoch 1/10 Iteration: 3600 Avg. Training loss: 4.7120 1.9483 sec/batch\n",
      "Epoch 1/10 Iteration: 3700 Avg. Training loss: 4.7153 1.9552 sec/batch\n",
      "Epoch 1/10 Iteration: 3800 Avg. Training loss: 4.7332 1.9515 sec/batch\n",
      "Epoch 1/10 Iteration: 3900 Avg. Training loss: 4.7166 1.9363 sec/batch\n",
      "Epoch 1/10 Iteration: 4000 Avg. Training loss: 4.6537 1.9370 sec/batch\n",
      "Nearest to it: speculate, notably, laden, chlorofluorocarbons, combinations, alsace, consultation, tradition,\n",
      "Nearest to four: eight, nine, seven, wb, forcefully, rumours, harpercollins, bat,\n",
      "Nearest to called: quebec, help, pug, supers, isolation, rooming, rosalyn, gambit,\n",
      "Nearest to th: scholarly, sizable, raised, under, stipulation, instrumentalists, dionysius, century,\n",
      "Nearest to years: infocom, rocker, pennsylvania, weasel, recalcitrant, wallace, harvest, circulating,\n",
      "Nearest to were: horton, garagiola, fifth, speed, great, broad, hadrian, last,\n",
      "Nearest to their: deterioration, saloon, formative, malted, mugabe, fermionic, nixon, gradually,\n",
      "Nearest to other: usually, cavers, vitro, syllabic, sofa, upgrades, babylonian, differing,\n",
      "Nearest to file: pancreatitis, rivaled, computing, editors, ernie, strings, labiodental, loar,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest to construction: crawling, remembrance, kimberley, protected, southside, motorway, disappear, instituted,\n",
      "Nearest to except: encapsulation, rafael, nat, pieces, succesor, keyword, grimwood, introduces,\n",
      "Nearest to shows: johannesburg, martial, learned, manslaughter, modules, dresden, customer, integumentary,\n",
      "Nearest to articles: gosh, balto, williams, manly, tested, basemen, expiration, phoenix,\n",
      "Nearest to grand: firings, catatonia, tirpitz, brodie, altercation, scandal, leverage, accolades,\n",
      "Nearest to units: lengths, watt, ineffective, alamogordo, raincoat, asimo, dalton, growing,\n",
      "Nearest to resources: rewrote, supplies, fiercest, posteriori, ou, reasonably, quorum, firenze,\n",
      "Epoch 1/10 Iteration: 4100 Avg. Training loss: 4.6552 1.9598 sec/batch\n",
      "Epoch 1/10 Iteration: 4200 Avg. Training loss: 4.6691 1.9276 sec/batch\n",
      "Epoch 1/10 Iteration: 4300 Avg. Training loss: 4.6365 1.9566 sec/batch\n",
      "Epoch 1/10 Iteration: 4400 Avg. Training loss: 4.6425 1.9323 sec/batch\n",
      "Epoch 1/10 Iteration: 4500 Avg. Training loss: 4.6279 1.9426 sec/batch\n",
      "Epoch 1/10 Iteration: 4600 Avg. Training loss: 4.6277 1.9529 sec/batch\n",
      "Epoch 2/10 Iteration: 4700 Avg. Training loss: 4.5786 1.3936 sec/batch\n",
      "Epoch 2/10 Iteration: 4800 Avg. Training loss: 4.5441 1.9464 sec/batch\n",
      "Epoch 2/10 Iteration: 4900 Avg. Training loss: 4.5191 1.9475 sec/batch\n",
      "Epoch 2/10 Iteration: 5000 Avg. Training loss: 4.5119 1.9406 sec/batch\n",
      "Nearest to it: speculate, notably, laden, combinations, chlorofluorocarbons, unvoiced, bundled, bulges,\n",
      "Nearest to four: nine, eight, seven, wb, six, harpercollins, harpsichordist, danny,\n",
      "Nearest to called: pug, supers, help, quebec, rooming, isolation, hiram, gambit,\n",
      "Nearest to th: scholarly, sizable, under, instrumentalists, century, raised, stipulation, manzikert,\n",
      "Nearest to years: infocom, rocker, female, recalcitrant, wallace, weasel, successive, pennsylvania,\n",
      "Nearest to were: horton, garagiola, broad, great, last, eec, hadrian, fifth,\n",
      "Nearest to their: deterioration, saloon, metron, malted, formative, fermionic, gradually, zoo,\n",
      "Nearest to other: usually, vitro, cavers, sofa, upgrades, syllabic, navigation, equivalent,\n",
      "Nearest to file: computing, rivaled, editors, nostra, pancreatitis, strings, ernie, obtuse,\n",
      "Nearest to construction: crawling, protected, kimberley, remembrance, southside, disasters, motorway, endow,\n",
      "Nearest to except: encapsulation, pieces, keyword, rafael, introduces, seiy, succesor, nat,\n",
      "Nearest to shows: johannesburg, martial, learned, manslaughter, modules, uplands, dresden, lena,\n",
      "Nearest to articles: balto, manly, basemen, gosh, miscible, expiration, tchaikovsky, phoenix,\n",
      "Nearest to grand: firings, catatonia, brodie, tirpitz, parishioners, altercation, feldman, scandal,\n",
      "Nearest to units: lengths, alamogordo, watt, raincoat, ineffective, jealously, endpoint, lard,\n",
      "Nearest to resources: rewrote, supplies, fiercest, posteriori, firenze, eva, ou, quorum,\n",
      "Epoch 2/10 Iteration: 5100 Avg. Training loss: 4.4828 1.9761 sec/batch\n",
      "Epoch 2/10 Iteration: 5200 Avg. Training loss: 4.5044 1.9430 sec/batch\n",
      "Epoch 2/10 Iteration: 5300 Avg. Training loss: 4.4704 1.9460 sec/batch\n",
      "Epoch 2/10 Iteration: 5400 Avg. Training loss: 4.5277 1.9430 sec/batch\n",
      "Epoch 2/10 Iteration: 5500 Avg. Training loss: 4.4936 1.9425 sec/batch\n",
      "Epoch 2/10 Iteration: 5600 Avg. Training loss: 4.4712 1.9447 sec/batch\n",
      "Epoch 2/10 Iteration: 5700 Avg. Training loss: 4.4620 2.0333 sec/batch\n",
      "Epoch 2/10 Iteration: 5800 Avg. Training loss: 4.4118 2.0552 sec/batch\n",
      "Epoch 2/10 Iteration: 5900 Avg. Training loss: 4.4394 1.9505 sec/batch\n",
      "Epoch 2/10 Iteration: 6000 Avg. Training loss: 4.4316 1.9467 sec/batch\n",
      "Nearest to it: speculate, notably, seemed, bundled, laden, bulges, combinations, chlorofluorocarbons,\n",
      "Nearest to four: wb, eight, six, nine, okinawa, harpercollins, seven, forcefully,\n",
      "Nearest to called: isolation, pug, quebec, help, supers, cartagena, hiram, garfunkel,\n",
      "Nearest to th: sizable, century, scholarly, instrumentalists, under, manzikert, raised, dionysius,\n",
      "Nearest to years: female, rocker, infocom, weasel, recalcitrant, successive, percent, circulating,\n",
      "Nearest to were: garagiola, horton, last, eec, broad, montevideo, speed, hadrian,\n",
      "Nearest to their: deterioration, malted, metron, suda, gradually, formative, saloon, mugabe,\n",
      "Nearest to other: usually, sofa, vitro, syllabic, upgrades, cavers, nhu, differing,\n",
      "Nearest to file: computing, device, rivaled, editors, strings, nostra, reboot, pancreatitis,\n",
      "Nearest to construction: protected, crawling, southside, motorway, kimberley, disasters, disappear, endow,\n",
      "Nearest to except: encapsulation, pieces, seiy, keyword, introduces, succesor, rafael, earnest,\n",
      "Nearest to shows: johannesburg, martial, manslaughter, learned, modules, lena, ewald, uplands,\n",
      "Nearest to articles: balto, manly, basemen, gosh, expiration, miscible, revise, probabilistic,\n",
      "Nearest to grand: firings, brodie, catatonia, tirpitz, milestone, premier, excavations, dyke,\n",
      "Nearest to units: lengths, alamogordo, triode, endpoint, raincoat, ineffective, quicksand, watt,\n",
      "Nearest to resources: rewrote, supplies, posteriori, ou, price, firenze, fiercest, finance,\n",
      "Epoch 2/10 Iteration: 6100 Avg. Training loss: 4.4445 1.9703 sec/batch\n",
      "Epoch 2/10 Iteration: 6200 Avg. Training loss: 4.4132 2.0154 sec/batch\n",
      "Epoch 2/10 Iteration: 6300 Avg. Training loss: 4.4491 1.9451 sec/batch\n",
      "Epoch 2/10 Iteration: 6400 Avg. Training loss: 4.4139 1.9393 sec/batch\n",
      "Epoch 2/10 Iteration: 6500 Avg. Training loss: 4.4223 1.9544 sec/batch\n",
      "Epoch 2/10 Iteration: 6600 Avg. Training loss: 4.4389 1.9557 sec/batch\n",
      "Epoch 2/10 Iteration: 6700 Avg. Training loss: 4.3737 1.9331 sec/batch\n",
      "Epoch 2/10 Iteration: 6800 Avg. Training loss: 4.3785 1.9460 sec/batch\n",
      "Epoch 2/10 Iteration: 6900 Avg. Training loss: 4.4064 1.9472 sec/batch\n",
      "Epoch 2/10 Iteration: 7000 Avg. Training loss: 4.3627 1.9350 sec/batch\n",
      "Nearest to it: speculate, chlorofluorocarbons, unvoiced, notably, combinations, bundled, edif, seemed,\n",
      "Nearest to four: eight, wb, six, seven, nine, harpercollins, okinawa, five,\n",
      "Nearest to called: isolation, pashtunistan, garfunkel, quebec, supers, generic, pug, decompositions,\n",
      "Nearest to th: century, sizable, scholarly, manzikert, instrumentalists, waxed, dionysius, meles,\n",
      "Nearest to years: female, rocker, recalcitrant, weasel, infocom, quelling, percent, successive,\n",
      "Nearest to were: garagiola, horton, montevideo, eec, last, questioning, great, berkshire,\n",
      "Nearest to their: deterioration, malted, suda, metron, gradually, either, formative, cantilever,\n",
      "Nearest to other: usually, sofa, vitro, syllabic, nhu, cavers, differing, fornication,\n",
      "Nearest to file: computing, device, editors, software, rivaled, system, strings, reboot,\n",
      "Nearest to construction: southside, motorway, protected, crawling, kimberley, appreciably, rashomon, talc,\n",
      "Nearest to except: encapsulation, seiy, keyword, pieces, occurrences, succesor, rafael, earnest,\n",
      "Nearest to shows: johannesburg, martial, learned, manslaughter, modules, ewald, lena, motion,\n",
      "Nearest to articles: balto, manly, gosh, basemen, athleticism, liturgy, expiration, cobe,\n",
      "Nearest to grand: firings, brodie, catatonia, dyke, tirpitz, altercation, excavations, milestone,\n",
      "Nearest to units: triode, lengths, watt, alamogordo, endpoint, nuclei, raincoat, quicksand,\n",
      "Nearest to resources: supplies, rewrote, posteriori, price, cacao, ou, finance, fiercest,\n",
      "Epoch 2/10 Iteration: 7100 Avg. Training loss: 4.3619 1.9671 sec/batch\n",
      "Epoch 2/10 Iteration: 7200 Avg. Training loss: 4.4088 1.9547 sec/batch\n",
      "Epoch 2/10 Iteration: 7300 Avg. Training loss: 4.3704 1.9406 sec/batch\n",
      "Epoch 2/10 Iteration: 7400 Avg. Training loss: 4.3751 1.9524 sec/batch\n",
      "Epoch 2/10 Iteration: 7500 Avg. Training loss: 4.4051 1.9591 sec/batch\n",
      "Epoch 2/10 Iteration: 7600 Avg. Training loss: 4.3721 1.9424 sec/batch\n",
      "Epoch 2/10 Iteration: 7700 Avg. Training loss: 4.3833 1.9637 sec/batch\n",
      "Epoch 2/10 Iteration: 7800 Avg. Training loss: 4.3937 1.9478 sec/batch\n",
      "Epoch 2/10 Iteration: 7900 Avg. Training loss: 4.3308 1.9384 sec/batch\n",
      "Epoch 2/10 Iteration: 8000 Avg. Training loss: 4.3480 1.9517 sec/batch\n",
      "Nearest to it: speculate, chlorofluorocarbons, unvoiced, bundled, edif, seemed, notably, above,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest to four: eight, six, seven, wb, five, nine, okinawa, forcefully,\n",
      "Nearest to called: isolation, supers, pashtunistan, quebec, garfunkel, decompositions, germaine, pug,\n",
      "Nearest to th: century, sizable, scholarly, manzikert, dionysius, instrumentalists, survived, waxed,\n",
      "Nearest to years: female, weasel, rocker, quelling, recalcitrant, successive, percent, cluttered,\n",
      "Nearest to were: montevideo, garagiola, eec, great, questioning, last, cavalli, horton,\n",
      "Nearest to their: deterioration, malted, metron, gradually, fermionic, suda, either, cantilever,\n",
      "Nearest to other: usually, sofa, vitro, nhu, dialling, lightsaber, fornication, constructionism,\n",
      "Nearest to file: computing, device, software, editors, reboot, encode, zseries, windows,\n",
      "Nearest to construction: southside, motorway, protected, crawling, kimberley, appreciably, talc, disasters,\n",
      "Nearest to except: encapsulation, seiy, earnest, succesor, rafael, keyword, pieces, mps,\n",
      "Nearest to shows: manslaughter, modules, adb, johannesburg, learned, martial, electrostatic, ewald,\n",
      "Nearest to articles: balto, takla, manly, cobe, revise, gosh, expiration, athleticism,\n",
      "Nearest to grand: firings, milestone, catatonia, tirpitz, brodie, scandal, excavations, premier,\n",
      "Nearest to units: triode, watt, alamogordo, conifer, quicksand, lengths, raincoat, gulag,\n",
      "Nearest to resources: supplies, rewrote, posteriori, quaternary, cacao, price, finance, fiercest,\n",
      "Epoch 2/10 Iteration: 8100 Avg. Training loss: 4.3434 1.9789 sec/batch\n",
      "Epoch 2/10 Iteration: 8200 Avg. Training loss: 4.2840 1.9496 sec/batch\n",
      "Epoch 2/10 Iteration: 8300 Avg. Training loss: 4.3937 1.9613 sec/batch\n",
      "Epoch 2/10 Iteration: 8400 Avg. Training loss: 4.3591 1.9579 sec/batch\n",
      "Epoch 2/10 Iteration: 8500 Avg. Training loss: 4.3839 1.9522 sec/batch\n",
      "Epoch 2/10 Iteration: 8600 Avg. Training loss: 4.3042 1.9557 sec/batch\n",
      "Epoch 2/10 Iteration: 8700 Avg. Training loss: 4.3087 1.9256 sec/batch\n",
      "Epoch 2/10 Iteration: 8800 Avg. Training loss: 4.3380 1.9525 sec/batch\n",
      "Epoch 2/10 Iteration: 8900 Avg. Training loss: 4.1975 1.9497 sec/batch\n",
      "Epoch 2/10 Iteration: 9000 Avg. Training loss: 4.2959 1.9351 sec/batch\n",
      "Nearest to it: chlorofluorocarbons, speculate, edif, unvoiced, bundled, seemed, combinations, smart,\n",
      "Nearest to four: eight, six, seven, nine, five, wb, two, okinawa,\n",
      "Nearest to called: supers, isolation, garfunkel, decompositions, pashtunistan, generic, quebec, dingo,\n",
      "Nearest to th: century, sizable, scholarly, manzikert, ringway, waxed, meles, dionysius,\n",
      "Nearest to years: female, male, population, percent, age, quelling, declining, recalcitrant,\n",
      "Nearest to were: montevideo, garagiola, eec, questioning, speed, marks, horton, angelique,\n",
      "Nearest to their: deterioration, malted, metron, gradually, fermionic, saloon, sverdlovsk, formative,\n",
      "Nearest to other: usually, sofa, vitro, lightsaber, nhu, fornication, dialling, syllabic,\n",
      "Nearest to file: computing, software, zseries, windows, encode, device, editors, reboot,\n",
      "Nearest to construction: southside, protected, motorway, crawling, kimberley, appreciably, disasters, talc,\n",
      "Nearest to except: encapsulation, seiy, keyword, earnest, rafael, succesor, pieces, nat,\n",
      "Nearest to shows: manslaughter, lena, johannesburg, jazz, martial, learned, modules, fan,\n",
      "Nearest to articles: balto, manly, takla, revise, cobe, quotes, liturgy, gosh,\n",
      "Nearest to grand: firings, chiefs, milestone, brodie, scandal, tirpitz, catatonia, dyke,\n",
      "Nearest to units: watt, triode, alamogordo, conifer, density, quicksand, gulag, endpoint,\n",
      "Nearest to resources: supplies, rewrote, cacao, posteriori, quaternary, finance, fiercest, funding,\n",
      "Epoch 2/10 Iteration: 9100 Avg. Training loss: 4.3001 1.9762 sec/batch\n",
      "Epoch 2/10 Iteration: 9200 Avg. Training loss: 4.3039 1.9461 sec/batch\n",
      "Epoch 3/10 Iteration: 9300 Avg. Training loss: 4.3314 0.8505 sec/batch\n",
      "Epoch 3/10 Iteration: 9400 Avg. Training loss: 4.2359 1.9505 sec/batch\n",
      "Epoch 3/10 Iteration: 9500 Avg. Training loss: 4.2132 1.9704 sec/batch\n",
      "Epoch 3/10 Iteration: 9600 Avg. Training loss: 4.2265 1.9482 sec/batch\n",
      "Epoch 3/10 Iteration: 9700 Avg. Training loss: 4.2191 1.9463 sec/batch\n",
      "Epoch 3/10 Iteration: 9800 Avg. Training loss: 4.2123 1.9521 sec/batch\n",
      "Epoch 3/10 Iteration: 9900 Avg. Training loss: 4.2266 1.9443 sec/batch\n",
      "Epoch 3/10 Iteration: 10000 Avg. Training loss: 4.1771 1.9491 sec/batch\n",
      "Nearest to it: chlorofluorocarbons, speculate, unvoiced, neon, seemed, above, bundled, edif,\n",
      "Nearest to four: eight, seven, six, five, nine, wb, two, ndel,\n",
      "Nearest to called: supers, isolation, decompositions, quebec, germaine, garfunkel, pashtunistan, hiram,\n",
      "Nearest to th: century, manzikert, sizable, ringway, scholarly, survived, waxed, meles,\n",
      "Nearest to years: female, percent, male, population, cluttered, fernando, quelling, declining,\n",
      "Nearest to were: montevideo, garagiola, speed, eec, last, questioning, angelique, wheel,\n",
      "Nearest to their: metron, gradually, deterioration, fermionic, made, malted, suda, either,\n",
      "Nearest to other: usually, sofa, lightsaber, vitro, constructionism, fornication, nhu, use,\n",
      "Nearest to file: zseries, encode, reboot, editors, computing, windows, nostra, software,\n",
      "Nearest to construction: southside, motorway, protected, appreciably, crawling, disasters, zr, kimberley,\n",
      "Nearest to except: encapsulation, seiy, earnest, keyword, rafael, succesor, introduces, emaciated,\n",
      "Nearest to shows: manslaughter, jazz, modules, learned, martial, johannesburg, borkou, scrabble,\n",
      "Nearest to articles: balto, takla, cobe, revise, manly, liturgy, athleticism, subscriptions,\n",
      "Nearest to grand: firings, milestone, dyke, chiefs, marching, feldman, brodie, catatonia,\n",
      "Nearest to units: quicksand, triode, alamogordo, conifer, watt, density, gulag, operations,\n",
      "Nearest to resources: cacao, supplies, rewrote, quaternary, posteriori, price, cois, neoconservative,\n",
      "Epoch 3/10 Iteration: 10100 Avg. Training loss: 4.2127 1.9590 sec/batch\n",
      "Epoch 3/10 Iteration: 10200 Avg. Training loss: 4.2271 1.9476 sec/batch\n",
      "Epoch 3/10 Iteration: 10300 Avg. Training loss: 4.2220 1.9563 sec/batch\n",
      "Epoch 3/10 Iteration: 10400 Avg. Training loss: 4.1430 1.9384 sec/batch\n",
      "Epoch 3/10 Iteration: 10500 Avg. Training loss: 4.1874 1.9571 sec/batch\n",
      "Epoch 3/10 Iteration: 10600 Avg. Training loss: 4.1835 1.9465 sec/batch\n",
      "Epoch 3/10 Iteration: 10700 Avg. Training loss: 4.1422 1.9304 sec/batch\n",
      "Epoch 3/10 Iteration: 10800 Avg. Training loss: 4.2094 1.9541 sec/batch\n",
      "Epoch 3/10 Iteration: 10900 Avg. Training loss: 4.1900 1.9554 sec/batch\n",
      "Epoch 3/10 Iteration: 11000 Avg. Training loss: 4.1788 1.9366 sec/batch\n",
      "Nearest to it: bundled, seemed, speculate, edif, chlorofluorocarbons, unvoiced, notably, neon,\n",
      "Nearest to four: eight, seven, six, five, wb, two, nine, okinawa,\n",
      "Nearest to called: supers, isolation, garfunkel, decompositions, quebec, smp, germaine, hiram,\n",
      "Nearest to th: century, manzikert, sizable, ringway, scholarly, waxed, dionysius, survived,\n",
      "Nearest to years: female, quelling, cluttered, male, age, percent, successive, declining,\n",
      "Nearest to were: montevideo, garagiola, speed, eec, decoration, picaresque, angelique, questioning,\n",
      "Nearest to their: metron, gradually, either, deterioration, made, functioning, sverdlovsk, malted,\n",
      "Nearest to other: usually, vitro, lightsaber, sofa, constructionism, nhu, dialling, use,\n",
      "Nearest to file: zseries, encode, reboot, computing, device, editors, windows, wiktionary,\n",
      "Nearest to construction: motorway, southside, appreciably, protected, kimberley, talc, disasters, crawling,\n",
      "Nearest to except: encapsulation, seiy, earnest, keyword, pieces, succesor, emaciated, introduces,\n",
      "Nearest to shows: scrabble, learned, johannesburg, jazz, manslaughter, fan, modules, vigen,\n",
      "Nearest to articles: balto, merino, publications, valletta, revise, cobe, subscriptions, takla,\n",
      "Nearest to grand: firings, milestone, chiefs, lithuanian, dyke, marching, brodie, tirpitz,\n",
      "Nearest to units: triode, quicksand, watt, conifer, alamogordo, density, endpoint, gulag,\n",
      "Nearest to resources: cacao, supplies, rewrote, quaternary, posteriori, cois, sticker, ou,\n",
      "Epoch 3/10 Iteration: 11100 Avg. Training loss: 4.1671 1.9792 sec/batch\n",
      "Epoch 3/10 Iteration: 11200 Avg. Training loss: 4.2241 1.9375 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 Iteration: 11300 Avg. Training loss: 4.1823 1.9351 sec/batch\n",
      "Epoch 3/10 Iteration: 11400 Avg. Training loss: 4.1453 1.9543 sec/batch\n",
      "Epoch 3/10 Iteration: 11500 Avg. Training loss: 4.1597 1.9248 sec/batch\n",
      "Epoch 3/10 Iteration: 11600 Avg. Training loss: 4.1746 1.9437 sec/batch\n",
      "Epoch 3/10 Iteration: 11700 Avg. Training loss: 4.2027 1.9558 sec/batch\n",
      "Epoch 3/10 Iteration: 11800 Avg. Training loss: 4.1802 1.9241 sec/batch\n",
      "Epoch 3/10 Iteration: 11900 Avg. Training loss: 4.1471 1.9552 sec/batch\n",
      "Epoch 3/10 Iteration: 12000 Avg. Training loss: 4.1943 1.9492 sec/batch\n",
      "Nearest to it: seemed, edif, bundled, chlorofluorocarbons, unvoiced, speculate, combinations, above,\n",
      "Nearest to four: eight, five, six, seven, two, nine, one, wb,\n",
      "Nearest to called: supers, isolation, garfunkel, generic, quebec, decompositions, pashtunistan, chromatids,\n",
      "Nearest to th: century, manzikert, scholarly, dionysius, sizable, ringway, waxed, survived,\n",
      "Nearest to years: female, male, age, quelling, cluttered, successive, population, fernando,\n",
      "Nearest to were: montevideo, garagiola, speed, eec, picaresque, questioning, angelique, decoration,\n",
      "Nearest to their: metron, cantilever, gradually, either, deterioration, fermionic, sverdlovsk, functioning,\n",
      "Nearest to other: usually, sofa, constructionism, nhu, vitro, lightsaber, dialling, written,\n",
      "Nearest to file: encode, zseries, reboot, editors, computing, nix, email, software,\n",
      "Nearest to construction: southside, motorway, appreciably, disasters, protected, rashomon, kimberley, zr,\n",
      "Nearest to except: encapsulation, seiy, earnest, pieces, introduces, keyword, emaciated, rafael,\n",
      "Nearest to shows: scrabble, modules, fan, vigen, learned, johannesburg, martial, lena,\n",
      "Nearest to articles: balto, merino, takla, publications, bibliography, cobe, revise, expiration,\n",
      "Nearest to grand: firings, milestone, chiefs, lithuanian, marching, tirpitz, destabilizing, catatonia,\n",
      "Nearest to units: watt, triode, quicksand, density, conifer, alamogordo, gulag, endpoint,\n",
      "Nearest to resources: cacao, rewrote, quaternary, supplies, sticker, cois, posteriori, neoconservative,\n",
      "Epoch 3/10 Iteration: 12100 Avg. Training loss: 4.1905 1.9580 sec/batch\n",
      "Epoch 3/10 Iteration: 12200 Avg. Training loss: 4.1462 1.9684 sec/batch\n",
      "Epoch 3/10 Iteration: 12300 Avg. Training loss: 4.2053 1.9478 sec/batch\n",
      "Epoch 3/10 Iteration: 12400 Avg. Training loss: 4.2030 1.9381 sec/batch\n",
      "Epoch 3/10 Iteration: 12500 Avg. Training loss: 4.1111 1.9498 sec/batch\n",
      "Epoch 3/10 Iteration: 12600 Avg. Training loss: 4.1374 1.9432 sec/batch\n",
      "Epoch 3/10 Iteration: 12700 Avg. Training loss: 4.1834 1.9370 sec/batch\n",
      "Epoch 3/10 Iteration: 12800 Avg. Training loss: 4.1463 1.9533 sec/batch\n",
      "Epoch 3/10 Iteration: 12900 Avg. Training loss: 4.1954 1.9490 sec/batch\n",
      "Epoch 3/10 Iteration: 13000 Avg. Training loss: 4.2135 1.9435 sec/batch\n",
      "Nearest to it: seemed, chlorofluorocarbons, edif, bundled, unvoiced, supposing, speculate, above,\n",
      "Nearest to four: eight, five, six, seven, two, one, nine, three,\n",
      "Nearest to called: supers, isolation, garfunkel, smp, quebec, pashtunistan, decompositions, generic,\n",
      "Nearest to th: century, manzikert, sizable, dionysius, ringway, waxed, england, survived,\n",
      "Nearest to years: female, male, age, year, fernando, cluttered, population, quelling,\n",
      "Nearest to were: montevideo, garagiola, picaresque, speed, angelique, nbi, questioning, decoration,\n",
      "Nearest to their: metron, either, made, cantilever, deterioration, gradually, fermionic, sverdlovsk,\n",
      "Nearest to other: usually, lightsaber, sofa, constructionism, nhu, dialling, vitro, gardnerian,\n",
      "Nearest to file: zseries, encode, reboot, nix, rivaled, nostra, email, editors,\n",
      "Nearest to construction: southside, motorway, appreciably, disasters, rashomon, kimberley, protected, zr,\n",
      "Nearest to except: earnest, seiy, encapsulation, rafael, masse, emaciated, introduces, pieces,\n",
      "Nearest to shows: scrabble, learned, fan, borkou, modules, jazz, vigen, pontificia,\n",
      "Nearest to articles: balto, takla, revise, bibliography, merino, expiration, quotes, publications,\n",
      "Nearest to grand: firings, milestone, chiefs, chlorus, lithuanian, marching, tirpitz, ostpolitik,\n",
      "Nearest to units: quicksand, triode, gulag, conifer, watt, alamogordo, density, endpoint,\n",
      "Nearest to resources: cacao, rewrote, supplies, quaternary, ore, fiercest, cois, sticker,\n",
      "Epoch 3/10 Iteration: 13100 Avg. Training loss: 4.2448 1.9952 sec/batch\n",
      "Epoch 3/10 Iteration: 13200 Avg. Training loss: 4.1467 1.9701 sec/batch\n",
      "Epoch 3/10 Iteration: 13300 Avg. Training loss: 4.1298 1.9419 sec/batch\n",
      "Epoch 3/10 Iteration: 13400 Avg. Training loss: 4.1260 1.9403 sec/batch\n",
      "Epoch 3/10 Iteration: 13500 Avg. Training loss: 4.0263 1.9261 sec/batch\n",
      "Epoch 3/10 Iteration: 13600 Avg. Training loss: 4.1434 1.9557 sec/batch\n",
      "Epoch 3/10 Iteration: 13700 Avg. Training loss: 4.1678 1.9443 sec/batch\n",
      "Epoch 3/10 Iteration: 13800 Avg. Training loss: 4.1602 1.9387 sec/batch\n",
      "Epoch 4/10 Iteration: 13900 Avg. Training loss: 4.1764 0.3100 sec/batch\n",
      "Epoch 4/10 Iteration: 14000 Avg. Training loss: 4.1373 1.9532 sec/batch\n",
      "Nearest to it: seemed, edif, chlorofluorocarbons, bundled, speculate, above, smart, unvoiced,\n",
      "Nearest to four: eight, five, six, seven, two, one, nine, three,\n",
      "Nearest to called: supers, decompositions, smp, chromatids, quebec, generic, garfunkel, isolation,\n",
      "Nearest to th: century, manzikert, ringway, sizable, dionysius, waxed, populaire, kupa,\n",
      "Nearest to years: female, male, age, year, population, cluttered, fernando, fertility,\n",
      "Nearest to were: montevideo, speed, garagiola, machines, decoration, intermediate, eec, picaresque,\n",
      "Nearest to their: metron, made, either, fermionic, cantilever, gradually, quadi, deterioration,\n",
      "Nearest to other: usually, sofa, lightsaber, nhu, dialling, constructionism, vitro, use,\n",
      "Nearest to file: zseries, encode, nix, reboot, nostra, rivaled, editors, computing,\n",
      "Nearest to construction: southside, motorway, appreciably, disasters, protected, rashomon, talc, kimberley,\n",
      "Nearest to except: seiy, encapsulation, earnest, introduces, pieces, rafael, masse, asparagus,\n",
      "Nearest to shows: scrabble, fan, pontificia, martial, borkou, jazz, learned, modules,\n",
      "Nearest to articles: balto, takla, revise, expiration, merino, publications, comprehensive, valletta,\n",
      "Nearest to grand: milestone, firings, chiefs, lithuanian, marching, chlorus, polis, ostpolitik,\n",
      "Nearest to units: quicksand, triode, gulag, watt, conifer, alamogordo, density, adjutant,\n",
      "Nearest to resources: cacao, rewrote, supplies, fiercest, sticker, cois, ore, quaternary,\n",
      "Epoch 4/10 Iteration: 14100 Avg. Training loss: 4.0726 1.9656 sec/batch\n",
      "Epoch 4/10 Iteration: 14200 Avg. Training loss: 4.0664 1.9593 sec/batch\n",
      "Epoch 4/10 Iteration: 14300 Avg. Training loss: 4.0896 1.9500 sec/batch\n",
      "Epoch 4/10 Iteration: 14400 Avg. Training loss: 4.0540 1.9298 sec/batch\n",
      "Epoch 4/10 Iteration: 14500 Avg. Training loss: 4.0548 1.9474 sec/batch\n",
      "Epoch 4/10 Iteration: 14600 Avg. Training loss: 4.0511 1.9345 sec/batch\n",
      "Epoch 4/10 Iteration: 14700 Avg. Training loss: 4.0904 1.9356 sec/batch\n",
      "Epoch 4/10 Iteration: 14800 Avg. Training loss: 4.1061 1.9565 sec/batch\n",
      "Epoch 4/10 Iteration: 14900 Avg. Training loss: 4.1179 1.9284 sec/batch\n",
      "Epoch 4/10 Iteration: 15000 Avg. Training loss: 4.0393 1.9410 sec/batch\n",
      "Nearest to it: bundled, seemed, chlorofluorocarbons, nicknames, edif, unvoiced, above, smart,\n",
      "Nearest to four: five, eight, seven, six, two, one, three, nine,\n",
      "Nearest to called: supers, quebec, decompositions, smp, generic, chromatids, isolation, pashtunistan,\n",
      "Nearest to th: century, manzikert, waxed, ringway, sizable, dionysius, mtsho, allosaurus,\n",
      "Nearest to years: female, age, year, male, cluttered, zero, fernando, population,\n",
      "Nearest to were: montevideo, speed, garagiola, machines, picaresque, decoration, intermediate, pleats,\n",
      "Nearest to their: metron, either, the, quadi, gradually, made, most, more,\n",
      "Nearest to other: usually, lightsaber, nhu, sofa, use, dialling, constructionism, vitro,\n",
      "Nearest to file: reboot, zseries, encode, nix, nostra, delete, workgroup, formats,\n",
      "Nearest to construction: southside, motorway, appreciably, building, disasters, rashomon, zr, chennai,\n",
      "Nearest to except: encapsulation, seiy, pieces, earnest, introduces, masse, osu, asparagus,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest to shows: borkou, pontificia, scrabble, fan, cfsp, johannesburg, martial, modules,\n",
      "Nearest to articles: balto, takla, subscriptions, merino, publications, com, comprehensive, oren,\n",
      "Nearest to grand: milestone, firings, lithuanian, chiefs, polis, marching, ostpolitik, chlorus,\n",
      "Nearest to units: quicksand, triode, density, gulag, alamogordo, conifer, mi, initialization,\n",
      "Nearest to resources: cacao, rewrote, fiercest, sticker, supplies, tempura, cois, ou,\n",
      "Epoch 4/10 Iteration: 15100 Avg. Training loss: 4.0226 1.9720 sec/batch\n",
      "Epoch 4/10 Iteration: 15200 Avg. Training loss: 4.0267 1.9326 sec/batch\n",
      "Epoch 4/10 Iteration: 15300 Avg. Training loss: 4.0168 1.9373 sec/batch\n",
      "Epoch 4/10 Iteration: 15400 Avg. Training loss: 4.0508 1.9487 sec/batch\n",
      "Epoch 4/10 Iteration: 15500 Avg. Training loss: 4.0786 1.9294 sec/batch\n",
      "Epoch 4/10 Iteration: 15600 Avg. Training loss: 4.0589 1.9580 sec/batch\n",
      "Epoch 4/10 Iteration: 15700 Avg. Training loss: 4.0578 1.9398 sec/batch\n",
      "Epoch 4/10 Iteration: 15800 Avg. Training loss: 4.1204 1.9246 sec/batch\n",
      "Epoch 4/10 Iteration: 15900 Avg. Training loss: 4.0580 1.9420 sec/batch\n",
      "Epoch 4/10 Iteration: 16000 Avg. Training loss: 4.0222 1.9407 sec/batch\n",
      "Nearest to it: bundled, chlorofluorocarbons, seemed, edif, smart, above, transceiver, only,\n",
      "Nearest to four: five, eight, seven, six, two, one, three, nine,\n",
      "Nearest to called: supers, smp, garfunkel, generic, chromatids, decompositions, isolation, quebec,\n",
      "Nearest to th: century, manzikert, waxed, dionysius, ringway, england, mtsho, sizable,\n",
      "Nearest to years: female, age, male, year, zero, cluttered, ago, average,\n",
      "Nearest to were: montevideo, garagiola, decoration, picaresque, machines, speed, pleats, eec,\n",
      "Nearest to their: either, metron, made, gradually, more, quadi, the, functioning,\n",
      "Nearest to other: usually, sofa, nhu, lightsaber, as, are, use, dialling,\n",
      "Nearest to file: reboot, zseries, encode, workgroup, delete, nix, files, rivaled,\n",
      "Nearest to construction: southside, motorway, appreciably, building, design, disasters, punta, talc,\n",
      "Nearest to except: encapsulation, seiy, earnest, introduces, masse, socony, pieces, dek,\n",
      "Nearest to shows: borkou, scrabble, pontificia, cfsp, martial, fan, capitalisation, schlei,\n",
      "Nearest to articles: balto, takla, merino, publications, subscriptions, bibliography, expiration, com,\n",
      "Nearest to grand: milestone, lithuanian, firings, polis, chiefs, ostpolitik, chlorus, marching,\n",
      "Nearest to units: quicksand, triode, density, mi, initialization, watt, gulag, alamogordo,\n",
      "Nearest to resources: cacao, rewrote, sticker, fiercest, tempura, ore, cois, supplies,\n",
      "Epoch 4/10 Iteration: 16100 Avg. Training loss: 4.0194 1.9645 sec/batch\n",
      "Epoch 4/10 Iteration: 16200 Avg. Training loss: 4.0974 1.9417 sec/batch\n",
      "Epoch 4/10 Iteration: 16300 Avg. Training loss: 4.0539 1.9344 sec/batch\n",
      "Epoch 4/10 Iteration: 16400 Avg. Training loss: 4.0436 1.9119 sec/batch\n",
      "Epoch 4/10 Iteration: 16500 Avg. Training loss: 4.0897 1.9300 sec/batch\n",
      "Epoch 4/10 Iteration: 16600 Avg. Training loss: 4.0680 1.9222 sec/batch\n",
      "Epoch 4/10 Iteration: 16700 Avg. Training loss: 4.0600 1.9187 sec/batch\n",
      "Epoch 4/10 Iteration: 16800 Avg. Training loss: 4.0332 1.9316 sec/batch\n",
      "Epoch 4/10 Iteration: 16900 Avg. Training loss: 4.0760 1.9325 sec/batch\n",
      "Epoch 4/10 Iteration: 17000 Avg. Training loss: 4.0603 1.9188 sec/batch\n",
      "Nearest to it: bundled, chlorofluorocarbons, seemed, edif, alsace, smart, only, supposing,\n",
      "Nearest to four: five, eight, six, seven, one, two, three, nine,\n",
      "Nearest to called: garfunkel, smp, supers, quebec, generic, pashtunistan, multiplicity, chromatids,\n",
      "Nearest to th: century, manzikert, waxed, dionysius, england, ringway, populaire, ola,\n",
      "Nearest to years: female, age, year, zero, male, ago, five, cluttered,\n",
      "Nearest to were: montevideo, picaresque, garagiola, decoration, last, intermediate, machines, eec,\n",
      "Nearest to their: either, metron, the, made, fermionic, gradually, quadi, bisexual,\n",
      "Nearest to other: usually, lightsaber, sofa, nhu, constructionism, dialling, use, notably,\n",
      "Nearest to file: reboot, nix, encode, zseries, delete, rivaled, nostra, editors,\n",
      "Nearest to construction: southside, motorway, appreciably, building, design, disasters, rashomon, talc,\n",
      "Nearest to except: earnest, seiy, dek, encapsulation, introduces, emaciated, rafael, masse,\n",
      "Nearest to shows: borkou, scrabble, pontificia, cfsp, modules, fan, capitalisation, gramophone,\n",
      "Nearest to articles: takla, com, balto, merino, expiration, revise, publications, comprehensive,\n",
      "Nearest to grand: milestone, lithuanian, firings, polis, destabilizing, chlorus, ostpolitik, chiefs,\n",
      "Nearest to units: quicksand, triode, density, mi, gulag, initialization, conifer, ernesto,\n",
      "Nearest to resources: cacao, rewrote, fiercest, notebooks, ore, tempura, sticker, neoconservative,\n",
      "Epoch 4/10 Iteration: 17100 Avg. Training loss: 4.0587 1.9334 sec/batch\n",
      "Epoch 4/10 Iteration: 17200 Avg. Training loss: 3.9990 1.9294 sec/batch\n",
      "Epoch 4/10 Iteration: 17300 Avg. Training loss: 4.0100 1.9219 sec/batch\n",
      "Epoch 4/10 Iteration: 17400 Avg. Training loss: 4.0451 1.9313 sec/batch\n",
      "Epoch 4/10 Iteration: 17500 Avg. Training loss: 4.0756 1.9385 sec/batch\n",
      "Epoch 4/10 Iteration: 17600 Avg. Training loss: 4.1247 1.9221 sec/batch\n",
      "Epoch 4/10 Iteration: 17700 Avg. Training loss: 4.1273 1.9320 sec/batch\n",
      "Epoch 4/10 Iteration: 17800 Avg. Training loss: 4.0246 1.9329 sec/batch\n",
      "Epoch 4/10 Iteration: 17900 Avg. Training loss: 4.0164 1.9041 sec/batch\n",
      "Epoch 4/10 Iteration: 18000 Avg. Training loss: 4.0717 1.9306 sec/batch\n",
      "Nearest to it: bundled, seemed, chlorofluorocarbons, edif, nicknames, alsace, smart, unvoiced,\n",
      "Nearest to four: five, eight, seven, six, one, two, three, nine,\n",
      "Nearest to called: smp, supers, decompositions, garfunkel, quebec, generic, chromatids, isolation,\n",
      "Nearest to th: century, manzikert, waxed, england, dionysius, ola, sizable, mtsho,\n",
      "Nearest to years: female, year, age, male, zero, ago, fernando, five,\n",
      "Nearest to were: montevideo, garagiola, machines, picaresque, decoration, nazi, last, pleats,\n",
      "Nearest to their: metron, either, made, quadi, the, gradually, fermionic, more,\n",
      "Nearest to other: usually, sofa, lightsaber, use, dialling, nhu, maximums, constructionism,\n",
      "Nearest to file: nix, zseries, encode, rivaled, reboot, delete, files, formats,\n",
      "Nearest to construction: southside, motorway, appreciably, building, disasters, design, talc, chennai,\n",
      "Nearest to except: introduces, dek, seiy, earnest, encapsulation, osu, rafael, nat,\n",
      "Nearest to shows: borkou, pontificia, scrabble, cfsp, modules, johannesburg, schlei, fan,\n",
      "Nearest to articles: balto, takla, merino, revise, expiration, publications, com, comprehensive,\n",
      "Nearest to grand: lithuanian, milestone, firings, polis, chiefs, ostpolitik, deftones, chlorus,\n",
      "Nearest to units: quicksand, triode, density, mi, gulag, conifer, residing, makeup,\n",
      "Nearest to resources: cacao, ore, fiercest, rewrote, erosion, notebooks, tempura, timber,\n",
      "Epoch 4/10 Iteration: 18100 Avg. Training loss: 3.9963 1.9590 sec/batch\n",
      "Epoch 4/10 Iteration: 18200 Avg. Training loss: 4.0238 1.9274 sec/batch\n",
      "Epoch 4/10 Iteration: 18300 Avg. Training loss: 4.0304 1.9485 sec/batch\n",
      "Epoch 4/10 Iteration: 18400 Avg. Training loss: 4.0403 1.9254 sec/batch\n",
      "Epoch 4/10 Iteration: 18500 Avg. Training loss: 4.0698 1.9242 sec/batch\n",
      "Epoch 5/10 Iteration: 18600 Avg. Training loss: 4.0601 1.7213 sec/batch\n",
      "Epoch 5/10 Iteration: 18700 Avg. Training loss: 4.0220 1.9278 sec/batch\n",
      "Epoch 5/10 Iteration: 18800 Avg. Training loss: 3.9788 1.9364 sec/batch\n",
      "Epoch 5/10 Iteration: 18900 Avg. Training loss: 3.9977 1.9588 sec/batch\n",
      "Epoch 5/10 Iteration: 19000 Avg. Training loss: 3.9787 1.9383 sec/batch\n",
      "Nearest to it: seemed, bundled, chlorofluorocarbons, edif, unvoiced, speculate, supposing, said,\n",
      "Nearest to four: five, eight, seven, six, one, two, three, nine,\n",
      "Nearest to called: supers, smp, quebec, decompositions, isolation, germaine, pashtunistan, br,\n",
      "Nearest to th: century, manzikert, waxed, ola, england, mtsho, st, dionysius,\n",
      "Nearest to years: female, year, age, male, ago, cluttered, five, zero,\n",
      "Nearest to were: machines, montevideo, garagiola, pleats, workstations, decoration, symbionts, last,\n",
      "Nearest to their: metron, made, either, gradually, the, quadi, formative, with,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest to other: usually, sofa, lightsaber, use, nhu, are, dialling, constructionism,\n",
      "Nearest to file: nix, encode, files, reboot, zseries, delete, nostra, formats,\n",
      "Nearest to construction: southside, motorway, building, appreciably, disasters, design, chennai, talc,\n",
      "Nearest to except: introduces, encapsulation, seiy, dek, earnest, emaciated, osu, nat,\n",
      "Nearest to shows: borkou, pontificia, scrabble, cfsp, modules, show, fan, schlei,\n",
      "Nearest to articles: takla, balto, revise, expiration, merino, publications, comprehensive, oren,\n",
      "Nearest to grand: lithuanian, milestone, polis, firings, chiefs, ostpolitik, chlorus, marching,\n",
      "Nearest to units: quicksand, triode, mi, density, conifer, gulag, makeup, airfoil,\n",
      "Nearest to resources: ore, cacao, rewrote, fiercest, notebooks, tempura, sticker, envoy,\n",
      "Epoch 5/10 Iteration: 19100 Avg. Training loss: 4.0013 1.9608 sec/batch\n",
      "Epoch 5/10 Iteration: 19200 Avg. Training loss: 3.9490 1.9522 sec/batch\n",
      "Epoch 5/10 Iteration: 19300 Avg. Training loss: 4.0214 1.9295 sec/batch\n",
      "Epoch 5/10 Iteration: 19400 Avg. Training loss: 4.0262 1.9299 sec/batch\n",
      "Epoch 5/10 Iteration: 19500 Avg. Training loss: 4.0363 1.9473 sec/batch\n",
      "Epoch 5/10 Iteration: 19600 Avg. Training loss: 3.9925 1.9274 sec/batch\n",
      "Epoch 5/10 Iteration: 19700 Avg. Training loss: 3.9094 1.9350 sec/batch\n",
      "Epoch 5/10 Iteration: 19800 Avg. Training loss: 3.9773 1.9542 sec/batch\n",
      "Epoch 5/10 Iteration: 19900 Avg. Training loss: 3.9223 1.9212 sec/batch\n",
      "Epoch 5/10 Iteration: 20000 Avg. Training loss: 3.9848 1.9473 sec/batch\n",
      "Nearest to it: seemed, bundled, chlorofluorocarbons, only, spoon, edif, unvoiced, nicknames,\n",
      "Nearest to four: five, eight, two, six, seven, one, three, nine,\n",
      "Nearest to called: smp, supers, isolation, br, decompositions, forming, chromatids, hiram,\n",
      "Nearest to th: century, manzikert, waxed, mtsho, ringway, england, st, bonzos,\n",
      "Nearest to years: female, year, age, male, zero, five, ago, two,\n",
      "Nearest to were: machines, montevideo, garagiola, picaresque, pleats, last, decoration, julio,\n",
      "Nearest to their: either, the, metron, made, quadi, more, with, gradually,\n",
      "Nearest to other: usually, are, use, lightsaber, sofa, as, written, dialling,\n",
      "Nearest to file: encode, files, nix, rivaled, reboot, nostra, delete, formats,\n",
      "Nearest to construction: southside, motorway, building, appreciably, design, disasters, codification, chennai,\n",
      "Nearest to except: introduces, encapsulation, seiy, pieces, emaciated, masse, osu, earnest,\n",
      "Nearest to shows: borkou, cfsp, pontificia, scrabble, modules, show, schlei, gramophone,\n",
      "Nearest to articles: takla, publications, merino, revise, balto, expiration, com, comprehensive,\n",
      "Nearest to grand: lithuanian, milestone, polis, ostpolitik, chiefs, firings, vilnius, destabilizing,\n",
      "Nearest to units: quicksand, triode, mi, conifer, density, gulag, residing, makeup,\n",
      "Nearest to resources: cacao, ore, rewrote, tempura, notebooks, fiercest, envoy, sticker,\n",
      "Epoch 5/10 Iteration: 20100 Avg. Training loss: 3.9723 1.9561 sec/batch\n",
      "Epoch 5/10 Iteration: 20200 Avg. Training loss: 4.0263 1.9381 sec/batch\n",
      "Epoch 5/10 Iteration: 20300 Avg. Training loss: 3.9447 1.9298 sec/batch\n",
      "Epoch 5/10 Iteration: 20400 Avg. Training loss: 4.0050 1.9261 sec/batch\n",
      "Epoch 5/10 Iteration: 20500 Avg. Training loss: 4.0235 1.9545 sec/batch\n",
      "Epoch 5/10 Iteration: 20600 Avg. Training loss: 3.9566 1.9583 sec/batch\n",
      "Epoch 5/10 Iteration: 20700 Avg. Training loss: 3.9831 1.9542 sec/batch\n",
      "Epoch 5/10 Iteration: 20800 Avg. Training loss: 3.9982 1.9410 sec/batch\n",
      "Epoch 5/10 Iteration: 20900 Avg. Training loss: 3.9913 1.9338 sec/batch\n",
      "Epoch 5/10 Iteration: 21000 Avg. Training loss: 3.9755 1.9427 sec/batch\n",
      "Nearest to it: seemed, bundled, only, chlorofluorocarbons, edif, definable, said, spoon,\n",
      "Nearest to four: five, eight, one, six, two, seven, nine, three,\n",
      "Nearest to called: supers, br, smp, isolation, generic, garfunkel, forming, quebec,\n",
      "Nearest to th: century, manzikert, waxed, mtsho, england, st, ola, dionysius,\n",
      "Nearest to years: female, year, age, male, zero, five, ago, days,\n",
      "Nearest to were: machines, garagiola, pleats, montevideo, picaresque, symbionts, decoration, julio,\n",
      "Nearest to their: either, made, the, metron, more, most, bisexual, formative,\n",
      "Nearest to other: usually, are, use, constructionism, sofa, nhu, lightsaber, written,\n",
      "Nearest to file: files, encode, nix, reboot, rivaled, delete, nostra, browse,\n",
      "Nearest to construction: southside, motorway, building, design, appreciably, engineering, disasters, chennai,\n",
      "Nearest to except: introduces, dek, emaciated, osu, encapsulation, seiy, masse, pieces,\n",
      "Nearest to shows: borkou, cfsp, show, pontificia, modules, scrabble, gramophone, fan,\n",
      "Nearest to articles: takla, revise, merino, publications, expiration, balto, oren, comprehensive,\n",
      "Nearest to grand: lithuanian, milestone, ostpolitik, polis, deftones, destabilizing, vilnius, chiefs,\n",
      "Nearest to units: quicksand, density, triode, mi, conifer, gulag, residing, airfoil,\n",
      "Nearest to resources: tempura, ore, cacao, notebooks, rewrote, fiercest, envoy, integrator,\n",
      "Epoch 5/10 Iteration: 21100 Avg. Training loss: 4.0110 1.9678 sec/batch\n",
      "Epoch 5/10 Iteration: 21200 Avg. Training loss: 3.9889 1.9432 sec/batch\n",
      "Epoch 5/10 Iteration: 21300 Avg. Training loss: 3.9649 1.9305 sec/batch\n",
      "Epoch 5/10 Iteration: 21400 Avg. Training loss: 4.0316 1.9346 sec/batch\n",
      "Epoch 5/10 Iteration: 21500 Avg. Training loss: 4.0216 1.9449 sec/batch\n",
      "Epoch 5/10 Iteration: 21600 Avg. Training loss: 4.0072 1.9567 sec/batch\n",
      "Epoch 5/10 Iteration: 21700 Avg. Training loss: 3.9664 1.9263 sec/batch\n",
      "Epoch 5/10 Iteration: 21800 Avg. Training loss: 3.9755 1.9310 sec/batch\n",
      "Epoch 5/10 Iteration: 21900 Avg. Training loss: 3.9793 1.9237 sec/batch\n",
      "Epoch 5/10 Iteration: 22000 Avg. Training loss: 4.0153 1.9382 sec/batch\n",
      "Nearest to it: bundled, chlorofluorocarbons, seemed, edif, only, unvoiced, nicknames, definable,\n",
      "Nearest to four: five, eight, six, seven, one, two, three, nine,\n",
      "Nearest to called: smp, fulani, br, generic, supers, pashtunistan, declared, isolation,\n",
      "Nearest to th: century, manzikert, waxed, england, st, mtsho, ola, dionysius,\n",
      "Nearest to years: female, year, age, zero, male, five, ago, days,\n",
      "Nearest to were: machines, workstations, picaresque, montevideo, last, intermediate, symbionts, garagiola,\n",
      "Nearest to their: either, the, metron, more, with, most, quadi, multiple,\n",
      "Nearest to other: usually, use, are, sofa, as, lightsaber, constructionism, notably,\n",
      "Nearest to file: rivaled, nix, files, reboot, encode, nostra, delete, finalised,\n",
      "Nearest to construction: southside, building, motorway, design, appreciably, engineering, disasters, chennai,\n",
      "Nearest to except: introduces, dek, seiy, emaciated, osu, encapsulation, nat, lamp,\n",
      "Nearest to shows: borkou, modules, cfsp, show, pontificia, scrabble, schlei, ton,\n",
      "Nearest to articles: takla, revise, publications, balto, expiration, merino, oren, com,\n",
      "Nearest to grand: lithuanian, milestone, ostpolitik, polis, deftones, chiefs, vilnius, destabilizing,\n",
      "Nearest to units: quicksand, conifer, triode, mi, density, gulag, makeup, residing,\n",
      "Nearest to resources: ore, fiercest, tempura, envoy, notebooks, cacao, rewrote, supplies,\n",
      "Epoch 5/10 Iteration: 22100 Avg. Training loss: 3.9842 1.9597 sec/batch\n",
      "Epoch 5/10 Iteration: 22200 Avg. Training loss: 4.0806 1.9217 sec/batch\n",
      "Epoch 5/10 Iteration: 22300 Avg. Training loss: 4.0173 1.9369 sec/batch\n",
      "Epoch 5/10 Iteration: 22400 Avg. Training loss: 4.0538 1.9299 sec/batch\n",
      "Epoch 5/10 Iteration: 22500 Avg. Training loss: 3.9387 1.9180 sec/batch\n",
      "Epoch 5/10 Iteration: 22600 Avg. Training loss: 3.9532 1.8968 sec/batch\n",
      "Epoch 5/10 Iteration: 22700 Avg. Training loss: 3.9729 1.9168 sec/batch\n",
      "Epoch 5/10 Iteration: 22800 Avg. Training loss: 3.9365 1.9162 sec/batch\n",
      "Epoch 5/10 Iteration: 22900 Avg. Training loss: 3.9903 1.9156 sec/batch\n",
      "Epoch 5/10 Iteration: 23000 Avg. Training loss: 3.9631 1.9429 sec/batch\n",
      "Nearest to it: seemed, bundled, chlorofluorocarbons, edif, only, spoon, said, notably,\n",
      "Nearest to four: five, eight, one, six, two, seven, three, nine,\n",
      "Nearest to called: smp, generic, fulani, supers, br, decompositions, ionic, multiplicity,\n",
      "Nearest to th: century, manzikert, waxed, st, mtsho, england, ringway, meles,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest to years: female, year, age, zero, male, five, ago, mortality,\n",
      "Nearest to were: machines, workstations, montevideo, garagiola, symbionts, intermediate, pleats, picaresque,\n",
      "Nearest to their: either, most, metron, the, multiple, made, bitnet, with,\n",
      "Nearest to other: usually, use, are, as, sofa, lightsaber, such, to,\n",
      "Nearest to file: files, nix, rivaled, delete, reboot, encode, nostra, formats,\n",
      "Nearest to construction: southside, motorway, building, appreciably, design, engineering, disasters, chennai,\n",
      "Nearest to except: introduces, dek, encapsulation, seiy, osu, masse, nat, pieces,\n",
      "Nearest to shows: show, borkou, cfsp, modules, scrabble, pontificia, schlei, gramophone,\n",
      "Nearest to articles: takla, revise, publications, balto, merino, oren, expiration, comprehensive,\n",
      "Nearest to grand: lithuanian, milestone, ostpolitik, polis, vilnius, chiefs, chlorus, tempelhof,\n",
      "Nearest to units: quicksand, mi, conifer, density, triode, makeup, residing, gulag,\n",
      "Nearest to resources: ore, envoy, tempura, notebooks, fiercest, extremes, cacao, arable,\n",
      "Epoch 5/10 Iteration: 23100 Avg. Training loss: 4.0002 1.9666 sec/batch\n",
      "Epoch 6/10 Iteration: 23200 Avg. Training loss: 3.9883 1.1520 sec/batch\n",
      "Epoch 6/10 Iteration: 23300 Avg. Training loss: 3.9654 1.9147 sec/batch\n",
      "Epoch 6/10 Iteration: 23400 Avg. Training loss: 3.9287 1.9321 sec/batch\n",
      "Epoch 6/10 Iteration: 23500 Avg. Training loss: 3.9556 1.9221 sec/batch\n",
      "Epoch 6/10 Iteration: 23600 Avg. Training loss: 3.9090 1.9143 sec/batch\n",
      "Epoch 6/10 Iteration: 23700 Avg. Training loss: 3.9519 1.9219 sec/batch\n",
      "Epoch 6/10 Iteration: 23800 Avg. Training loss: 3.9238 1.9194 sec/batch\n",
      "Epoch 6/10 Iteration: 23900 Avg. Training loss: 3.9115 1.9289 sec/batch\n",
      "Epoch 6/10 Iteration: 24000 Avg. Training loss: 3.9659 1.9192 sec/batch\n",
      "Nearest to it: bundled, chlorofluorocarbons, only, seemed, spoon, edif, slightly, said,\n",
      "Nearest to four: five, eight, one, two, seven, six, three, zero,\n",
      "Nearest to called: smp, br, supers, generic, forming, kiswahili, multiplicity, fulani,\n",
      "Nearest to th: century, manzikert, waxed, st, mtsho, nd, brigade, england,\n",
      "Nearest to years: female, year, age, zero, male, five, ago, due,\n",
      "Nearest to were: machines, pleats, workstations, was, montevideo, last, garagiola, in,\n",
      "Nearest to their: either, with, the, most, metron, more, made, bitnet,\n",
      "Nearest to other: usually, use, are, as, sofa, lightsaber, such, constructionism,\n",
      "Nearest to file: files, nix, nostra, reboot, rivaled, delete, formats, encode,\n",
      "Nearest to construction: southside, building, motorway, design, appreciably, engineering, coefficient, disasters,\n",
      "Nearest to except: introduces, seiy, dek, osu, encapsulation, pieces, nat, emaciated,\n",
      "Nearest to shows: borkou, show, modules, scrabble, cfsp, pontificia, gramophone, whither,\n",
      "Nearest to articles: takla, revise, publications, balto, expiration, oren, merino, liturgy,\n",
      "Nearest to grand: lithuanian, milestone, polis, vilnius, ostpolitik, chiefs, chlorus, tempelhof,\n",
      "Nearest to units: mi, quicksand, makeup, residing, housing, density, triode, conifer,\n",
      "Nearest to resources: ore, tempura, fiercest, notebooks, envoy, cacao, extremes, arable,\n",
      "Epoch 6/10 Iteration: 24100 Avg. Training loss: 3.9435 1.9373 sec/batch\n",
      "Epoch 6/10 Iteration: 24200 Avg. Training loss: 3.9869 1.9215 sec/batch\n",
      "Epoch 6/10 Iteration: 24300 Avg. Training loss: 3.8657 1.9237 sec/batch\n",
      "Epoch 6/10 Iteration: 24400 Avg. Training loss: 3.9145 1.9543 sec/batch\n",
      "Epoch 6/10 Iteration: 24500 Avg. Training loss: 3.8922 1.9194 sec/batch\n",
      "Epoch 6/10 Iteration: 24600 Avg. Training loss: 3.8807 1.9119 sec/batch\n",
      "Epoch 6/10 Iteration: 24700 Avg. Training loss: 3.9274 1.9548 sec/batch\n",
      "Epoch 6/10 Iteration: 24800 Avg. Training loss: 3.9482 1.9357 sec/batch\n",
      "Epoch 6/10 Iteration: 24900 Avg. Training loss: 3.9148 1.9142 sec/batch\n",
      "Epoch 6/10 Iteration: 25000 Avg. Training loss: 3.9259 1.9287 sec/batch\n",
      "Nearest to it: only, bundled, chlorofluorocarbons, seemed, spoon, edif, said, definable,\n",
      "Nearest to four: five, eight, one, two, seven, six, three, zero,\n",
      "Nearest to called: smp, br, generic, multiplicity, forming, supers, chromatids, nucleoside,\n",
      "Nearest to th: century, manzikert, st, mtsho, waxed, nd, meles, ringway,\n",
      "Nearest to years: female, year, age, five, days, zero, male, ago,\n",
      "Nearest to were: pleats, machines, symbionts, picaresque, decoration, workstations, was, flagship,\n",
      "Nearest to their: either, with, the, most, quadi, metron, made, formative,\n",
      "Nearest to other: usually, are, as, use, such, sofa, to, written,\n",
      "Nearest to file: files, nix, delete, nostra, rivaled, reboot, encode, comprising,\n",
      "Nearest to construction: southside, building, design, motorway, appreciably, engineering, ieoh, coefficient,\n",
      "Nearest to except: introduces, pieces, seiy, emaciated, masse, encapsulation, lamp, osu,\n",
      "Nearest to shows: borkou, show, scrabble, modules, pontificia, cfsp, aired, whither,\n",
      "Nearest to articles: takla, revise, publications, oren, expiration, balto, merino, com,\n",
      "Nearest to grand: lithuanian, polis, milestone, ostpolitik, vilnius, chiefs, destabilizing, freemasonic,\n",
      "Nearest to units: quicksand, mi, makeup, triode, residing, conifer, housing, density,\n",
      "Nearest to resources: tempura, notebooks, ore, envoy, cacao, fiercest, extremes, integrator,\n",
      "Epoch 6/10 Iteration: 25100 Avg. Training loss: 4.0072 1.9412 sec/batch\n",
      "Epoch 6/10 Iteration: 25200 Avg. Training loss: 3.9552 1.9073 sec/batch\n",
      "Epoch 6/10 Iteration: 25300 Avg. Training loss: 3.9340 1.9152 sec/batch\n",
      "Epoch 6/10 Iteration: 25400 Avg. Training loss: 3.9272 1.9161 sec/batch\n",
      "Epoch 6/10 Iteration: 25500 Avg. Training loss: 3.9617 1.9124 sec/batch\n",
      "Epoch 6/10 Iteration: 25600 Avg. Training loss: 3.9456 1.9237 sec/batch\n",
      "Epoch 6/10 Iteration: 25700 Avg. Training loss: 3.9594 1.9153 sec/batch\n",
      "Epoch 6/10 Iteration: 25800 Avg. Training loss: 3.9109 1.9146 sec/batch\n",
      "Epoch 6/10 Iteration: 25900 Avg. Training loss: 3.9575 1.9071 sec/batch\n",
      "Epoch 6/10 Iteration: 26000 Avg. Training loss: 3.9694 1.9085 sec/batch\n",
      "Nearest to it: only, seemed, bundled, chlorofluorocarbons, edif, respecting, spoon, said,\n",
      "Nearest to four: five, two, eight, one, seven, six, three, zero,\n",
      "Nearest to called: smp, br, supers, generic, multiplicity, nucleoside, chromatids, fulani,\n",
      "Nearest to th: century, manzikert, st, mtsho, waxed, nd, england, dionysius,\n",
      "Nearest to years: female, year, age, zero, five, ago, days, male,\n",
      "Nearest to were: machines, excluded, symbionts, was, julio, preterism, pleats, picaresque,\n",
      "Nearest to their: either, with, most, multiple, metron, the, made, bitnet,\n",
      "Nearest to other: usually, are, use, as, such, sofa, lightsaber, constructionism,\n",
      "Nearest to file: files, nix, delete, nostra, encode, rivaled, reboot, carrel,\n",
      "Nearest to construction: southside, building, design, motorway, appreciably, engineering, ieoh, disasters,\n",
      "Nearest to except: introduces, pieces, dek, seiy, emaciated, asparagus, uninhabitable, osu,\n",
      "Nearest to shows: show, borkou, modules, pontificia, cfsp, scrabble, schlei, aired,\n",
      "Nearest to articles: publications, takla, revise, oren, expiration, merino, balto, com,\n",
      "Nearest to grand: lithuanian, polis, ostpolitik, milestone, freemasonic, vilnius, deftones, destabilizing,\n",
      "Nearest to units: makeup, mi, quicksand, residing, housing, conifer, density, triode,\n",
      "Nearest to resources: ore, envoy, tempura, notebooks, extremes, fiercest, cacao, integrator,\n",
      "Epoch 6/10 Iteration: 26100 Avg. Training loss: 3.9672 1.9618 sec/batch\n",
      "Epoch 6/10 Iteration: 26200 Avg. Training loss: 3.9406 1.9115 sec/batch\n",
      "Epoch 6/10 Iteration: 26300 Avg. Training loss: 3.9753 1.9151 sec/batch\n",
      "Epoch 6/10 Iteration: 26400 Avg. Training loss: 3.9030 1.9110 sec/batch\n",
      "Epoch 6/10 Iteration: 26500 Avg. Training loss: 3.9243 1.9217 sec/batch\n",
      "Epoch 6/10 Iteration: 26600 Avg. Training loss: 3.9566 1.9311 sec/batch\n",
      "Epoch 6/10 Iteration: 26700 Avg. Training loss: 3.8818 1.9481 sec/batch\n",
      "Epoch 6/10 Iteration: 26800 Avg. Training loss: 4.0165 1.9455 sec/batch\n",
      "Epoch 6/10 Iteration: 26900 Avg. Training loss: 4.0238 1.9437 sec/batch\n",
      "Epoch 6/10 Iteration: 27000 Avg. Training loss: 3.9953 1.9174 sec/batch\n",
      "Nearest to it: seemed, bundled, only, chlorofluorocarbons, edif, spoon, respecting, alia,\n",
      "Nearest to four: five, one, eight, two, seven, six, three, zero,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest to called: smp, fulani, generic, pashtunistan, kiswahili, br, multiplicity, supers,\n",
      "Nearest to th: century, manzikert, mtsho, waxed, st, nd, england, brigade,\n",
      "Nearest to years: female, year, age, days, zero, ago, five, due,\n",
      "Nearest to were: epidemic, symbionts, picaresque, machines, pleats, was, excluded, last,\n",
      "Nearest to their: the, either, with, metron, made, most, multiple, bitnet,\n",
      "Nearest to other: usually, use, as, are, such, lightsaber, to, notably,\n",
      "Nearest to file: files, delete, nostra, nix, reboot, rivaled, finalised, carrel,\n",
      "Nearest to construction: southside, design, building, motorway, engineering, appreciably, ieoh, disasters,\n",
      "Nearest to except: introduces, dek, proviso, seiy, pieces, nat, masse, asparagus,\n",
      "Nearest to shows: show, borkou, modules, pontificia, scrabble, cfsp, fanpage, snatcher,\n",
      "Nearest to articles: revise, takla, publications, merino, oren, expiration, balto, portals,\n",
      "Nearest to grand: lithuanian, polis, vilnius, ostpolitik, freemasonic, tempelhof, milestone, destabilizing,\n",
      "Nearest to units: quicksand, makeup, mi, residing, conifer, housing, density, gulag,\n",
      "Nearest to resources: ore, extremes, envoy, tempura, notebooks, arable, fiercest, cacao,\n",
      "Epoch 6/10 Iteration: 27100 Avg. Training loss: 3.9318 1.9705 sec/batch\n",
      "Epoch 6/10 Iteration: 27200 Avg. Training loss: 3.8929 1.9062 sec/batch\n",
      "Epoch 6/10 Iteration: 27300 Avg. Training loss: 3.9589 1.9168 sec/batch\n",
      "Epoch 6/10 Iteration: 27400 Avg. Training loss: 3.8568 1.9370 sec/batch\n",
      "Epoch 6/10 Iteration: 27500 Avg. Training loss: 3.9630 1.9184 sec/batch\n",
      "Epoch 6/10 Iteration: 27600 Avg. Training loss: 3.9347 1.9234 sec/batch\n",
      "Epoch 6/10 Iteration: 27700 Avg. Training loss: 3.9332 1.9286 sec/batch\n",
      "Epoch 7/10 Iteration: 27800 Avg. Training loss: 3.9909 0.6143 sec/batch\n",
      "Epoch 7/10 Iteration: 27900 Avg. Training loss: 3.9135 1.9285 sec/batch\n",
      "Epoch 7/10 Iteration: 28000 Avg. Training loss: 3.8970 1.9310 sec/batch\n",
      "Nearest to it: seemed, only, said, bundled, edif, spoon, chlorofluorocarbons, respecting,\n",
      "Nearest to four: five, one, eight, two, seven, six, three, zero,\n",
      "Nearest to called: smp, generic, forming, multiplicity, fulani, chromatids, kiswahili, br,\n",
      "Nearest to th: century, manzikert, mtsho, st, waxed, nd, england, brigade,\n",
      "Nearest to years: female, year, age, days, male, zero, five, due,\n",
      "Nearest to were: epidemic, symbionts, was, previously, vegetation, excluded, picaresque, pleats,\n",
      "Nearest to their: the, multiple, most, metron, either, gradually, made, with,\n",
      "Nearest to other: usually, as, use, are, such, to, lightsaber, sofa,\n",
      "Nearest to file: files, delete, nix, formats, nostra, reboot, finalised, carrel,\n",
      "Nearest to construction: southside, engineering, design, motorway, building, talc, appreciably, ieoh,\n",
      "Nearest to except: introduces, seiy, dek, masse, pieces, osu, emaciated, encapsulation,\n",
      "Nearest to shows: show, borkou, pontificia, modules, scrabble, aired, according, cfsp,\n",
      "Nearest to articles: revise, takla, publications, oren, merino, expiration, balto, tuileries,\n",
      "Nearest to grand: lithuanian, polis, vilnius, ostpolitik, chiefs, tempelhof, freemasonic, milestone,\n",
      "Nearest to units: mi, quicksand, makeup, residing, housing, conifer, density, triode,\n",
      "Nearest to resources: ore, envoy, notebooks, tempura, extremes, fiercest, arable, cacao,\n",
      "Epoch 7/10 Iteration: 28100 Avg. Training loss: 3.9020 1.9764 sec/batch\n",
      "Epoch 7/10 Iteration: 28200 Avg. Training loss: 3.8885 1.9091 sec/batch\n",
      "Epoch 7/10 Iteration: 28300 Avg. Training loss: 3.8939 1.9176 sec/batch\n",
      "Epoch 7/10 Iteration: 28400 Avg. Training loss: 3.9060 2.0095 sec/batch\n",
      "Epoch 7/10 Iteration: 28500 Avg. Training loss: 3.8565 1.9318 sec/batch\n",
      "Epoch 7/10 Iteration: 28600 Avg. Training loss: 3.9529 1.9344 sec/batch\n",
      "Epoch 7/10 Iteration: 28700 Avg. Training loss: 3.9088 1.9674 sec/batch\n",
      "Epoch 7/10 Iteration: 28800 Avg. Training loss: 3.9485 1.9415 sec/batch\n",
      "Epoch 7/10 Iteration: 28900 Avg. Training loss: 3.8203 1.9571 sec/batch\n",
      "Epoch 7/10 Iteration: 29000 Avg. Training loss: 3.8890 1.9343 sec/batch\n",
      "Nearest to it: only, seemed, bundled, said, spoon, chlorofluorocarbons, the, part,\n",
      "Nearest to four: five, two, one, eight, six, seven, three, zero,\n",
      "Nearest to called: smp, forming, kiswahili, generic, quebec, fulani, pashtunistan, inner,\n",
      "Nearest to th: century, manzikert, waxed, mtsho, st, nd, brigade, bealtaine,\n",
      "Nearest to years: female, year, age, zero, days, five, male, due,\n",
      "Nearest to were: pleats, symbionts, excluded, picaresque, ostia, last, epidemic, those,\n",
      "Nearest to their: most, the, either, with, they, metron, multiple, made,\n",
      "Nearest to other: as, are, usually, use, such, to, number, associated,\n",
      "Nearest to file: files, delete, nostra, carrel, reboot, nix, finalised, formats,\n",
      "Nearest to construction: southside, design, building, engineering, motorway, talc, appreciably, ieoh,\n",
      "Nearest to except: introduces, masse, pieces, seiy, proviso, dek, ectocervix, emaciated,\n",
      "Nearest to shows: borkou, pontificia, show, modules, cfsp, according, scrabble, schlei,\n",
      "Nearest to articles: revise, takla, publications, oren, merino, expiration, com, balto,\n",
      "Nearest to grand: lithuanian, polis, vilnius, tempelhof, ostpolitik, chiefs, milestone, freemasonic,\n",
      "Nearest to units: makeup, mi, quicksand, residing, housing, conifer, density, unit,\n",
      "Nearest to resources: ore, notebooks, tempura, extremes, envoy, cacao, arable, fiercest,\n",
      "Epoch 7/10 Iteration: 29100 Avg. Training loss: 3.8650 1.9535 sec/batch\n",
      "Epoch 7/10 Iteration: 29200 Avg. Training loss: 3.8379 1.9298 sec/batch\n",
      "Epoch 7/10 Iteration: 29300 Avg. Training loss: 3.9006 1.9313 sec/batch\n",
      "Epoch 7/10 Iteration: 29400 Avg. Training loss: 3.9355 1.9659 sec/batch\n",
      "Epoch 7/10 Iteration: 29500 Avg. Training loss: 3.8955 2.1656 sec/batch\n",
      "Epoch 7/10 Iteration: 29600 Avg. Training loss: 3.8855 2.2914 sec/batch\n",
      "Epoch 7/10 Iteration: 29700 Avg. Training loss: 3.9591 2.2491 sec/batch\n",
      "Epoch 7/10 Iteration: 29800 Avg. Training loss: 3.9003 2.3805 sec/batch\n",
      "Epoch 7/10 Iteration: 29900 Avg. Training loss: 3.8696 2.2975 sec/batch\n",
      "Epoch 7/10 Iteration: 30000 Avg. Training loss: 3.9114 2.4268 sec/batch\n",
      "Nearest to it: only, seemed, bundled, edif, spoon, said, but, respecting,\n",
      "Nearest to four: five, one, two, eight, seven, six, three, zero,\n",
      "Nearest to called: smp, forming, inner, such, chromatids, along, nucleoside, ionic,\n",
      "Nearest to th: century, mtsho, manzikert, st, waxed, nd, brigade, designated,\n",
      "Nearest to years: female, year, age, days, ago, due, five, zero,\n",
      "Nearest to were: excluded, last, previously, was, pleats, epidemic, symbionts, those,\n",
      "Nearest to their: they, either, the, most, multiple, with, metron, made,\n",
      "Nearest to other: as, are, usually, use, such, to, by, number,\n",
      "Nearest to file: files, delete, nostra, nix, finalised, carrel, magdalene, comprising,\n",
      "Nearest to construction: design, southside, building, motorway, engineering, ieoh, appreciably, dam,\n",
      "Nearest to except: introduces, seiy, proviso, masse, qsort, dek, councilor, emaciated,\n",
      "Nearest to shows: show, borkou, modules, pontificia, cfsp, according, scrabble, aired,\n",
      "Nearest to articles: revise, takla, publications, oren, merino, expiration, tuileries, balto,\n",
      "Nearest to grand: lithuanian, polis, freemasonic, vilnius, tempelhof, ostpolitik, destabilizing, surfing,\n",
      "Nearest to units: makeup, mi, residing, housing, quicksand, unit, conifer, density,\n",
      "Nearest to resources: tempura, ore, notebooks, envoy, extremes, cacao, arable, safeguarding,\n",
      "Epoch 7/10 Iteration: 30100 Avg. Training loss: 3.9406 2.2762 sec/batch\n",
      "Epoch 7/10 Iteration: 30200 Avg. Training loss: 3.9289 2.1623 sec/batch\n",
      "Epoch 7/10 Iteration: 30300 Avg. Training loss: 3.8937 2.1426 sec/batch\n",
      "Epoch 7/10 Iteration: 30400 Avg. Training loss: 3.9157 2.3759 sec/batch\n",
      "Epoch 7/10 Iteration: 30500 Avg. Training loss: 3.9178 1.9976 sec/batch\n",
      "Epoch 7/10 Iteration: 30600 Avg. Training loss: 3.8932 1.9251 sec/batch\n",
      "Epoch 7/10 Iteration: 30700 Avg. Training loss: 3.9114 1.9312 sec/batch\n",
      "Epoch 7/10 Iteration: 30800 Avg. Training loss: 3.9319 1.9305 sec/batch\n",
      "Epoch 7/10 Iteration: 30900 Avg. Training loss: 3.8978 1.9268 sec/batch\n",
      "Epoch 7/10 Iteration: 31000 Avg. Training loss: 3.8763 1.9170 sec/batch\n",
      "Nearest to it: only, seemed, bundled, spoon, edif, said, since, the,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest to four: five, one, two, eight, seven, six, three, zero,\n",
      "Nearest to called: smp, multiplicity, fulani, kiswahili, pashtunistan, unity, inner, sultanate,\n",
      "Nearest to th: century, mtsho, manzikert, waxed, st, nd, england, six,\n",
      "Nearest to years: female, year, age, days, zero, ago, due, five,\n",
      "Nearest to were: excluded, last, epidemic, previously, symbionts, was, various, picaresque,\n",
      "Nearest to their: either, they, multiple, the, with, most, metron, motorcyclists,\n",
      "Nearest to other: as, usually, are, use, such, to, associated, many,\n",
      "Nearest to file: files, finalised, carrel, encode, nostra, formats, nix, delete,\n",
      "Nearest to construction: design, southside, building, motorway, engineering, dam, appreciably, ieoh,\n",
      "Nearest to except: introduces, seiy, dek, omitted, masse, qsort, pieces, proviso,\n",
      "Nearest to shows: show, borkou, pontificia, modules, cfsp, scrabble, aired, according,\n",
      "Nearest to articles: revise, takla, merino, expiration, oren, publications, balto, tuileries,\n",
      "Nearest to grand: lithuanian, tempelhof, vilnius, freemasonic, polis, deftones, ostpolitik, surfing,\n",
      "Nearest to units: makeup, residing, mi, housing, quicksand, unit, density, conifer,\n",
      "Nearest to resources: tempura, ore, notebooks, envoy, extremes, cacao, arable, safeguarding,\n",
      "Epoch 7/10 Iteration: 31100 Avg. Training loss: 3.8555 1.9423 sec/batch\n",
      "Epoch 7/10 Iteration: 31200 Avg. Training loss: 3.9023 1.9209 sec/batch\n",
      "Epoch 7/10 Iteration: 31300 Avg. Training loss: 3.9098 1.9281 sec/batch\n",
      "Epoch 7/10 Iteration: 31400 Avg. Training loss: 3.9328 1.9342 sec/batch\n",
      "Epoch 7/10 Iteration: 31500 Avg. Training loss: 4.0046 1.9265 sec/batch\n",
      "Epoch 7/10 Iteration: 31600 Avg. Training loss: 3.9519 1.9151 sec/batch\n",
      "Epoch 7/10 Iteration: 31700 Avg. Training loss: 3.9058 1.9402 sec/batch\n",
      "Epoch 7/10 Iteration: 31800 Avg. Training loss: 3.8722 1.9055 sec/batch\n",
      "Epoch 7/10 Iteration: 31900 Avg. Training loss: 3.9062 1.9050 sec/batch\n",
      "Epoch 7/10 Iteration: 32000 Avg. Training loss: 3.8000 1.9169 sec/batch\n",
      "Nearest to it: only, seemed, bundled, spoon, said, edif, chlorofluorocarbons, violently,\n",
      "Nearest to four: five, two, one, seven, eight, six, three, zero,\n",
      "Nearest to called: smp, fulani, kiswahili, sent, lexically, sultanate, inner, multiplicity,\n",
      "Nearest to th: century, mtsho, waxed, manzikert, st, nd, six, designated,\n",
      "Nearest to years: female, year, zero, age, days, five, male, ago,\n",
      "Nearest to were: previously, was, ghettos, last, those, in, epidemic, many,\n",
      "Nearest to their: they, either, multiple, with, the, metron, most, made,\n",
      "Nearest to other: as, are, usually, use, to, such, in, number,\n",
      "Nearest to file: files, finalised, carrel, formats, encode, delete, nostra, admixture,\n",
      "Nearest to construction: southside, design, motorway, building, engineering, dam, ieoh, talc,\n",
      "Nearest to except: introduces, seiy, masse, dek, councilor, omitted, kuni, pieces,\n",
      "Nearest to shows: show, borkou, pontificia, aired, modules, scrabble, according, schlei,\n",
      "Nearest to articles: revise, takla, oren, publications, expiration, merino, balto, online,\n",
      "Nearest to grand: lithuanian, vilnius, tempelhof, freemasonic, polis, chiefs, ostpolitik, surfing,\n",
      "Nearest to units: makeup, mi, residing, housing, quicksand, unit, conifer, density,\n",
      "Nearest to resources: ore, notebooks, tempura, extremes, envoy, arable, cacao, safeguarding,\n",
      "Epoch 7/10 Iteration: 32100 Avg. Training loss: 3.9119 1.9544 sec/batch\n",
      "Epoch 7/10 Iteration: 32200 Avg. Training loss: 3.8893 1.9199 sec/batch\n",
      "Epoch 7/10 Iteration: 32300 Avg. Training loss: 3.9126 1.9214 sec/batch\n",
      "Epoch 8/10 Iteration: 32400 Avg. Training loss: 3.9182 0.0792 sec/batch\n",
      "Epoch 8/10 Iteration: 32500 Avg. Training loss: 3.9485 1.9267 sec/batch\n",
      "Epoch 8/10 Iteration: 32600 Avg. Training loss: 3.8947 1.9286 sec/batch\n",
      "Epoch 8/10 Iteration: 32700 Avg. Training loss: 3.8517 1.9214 sec/batch\n",
      "Epoch 8/10 Iteration: 32800 Avg. Training loss: 3.9170 1.9236 sec/batch\n",
      "Epoch 8/10 Iteration: 32900 Avg. Training loss: 3.8752 1.9248 sec/batch\n",
      "Epoch 8/10 Iteration: 33000 Avg. Training loss: 3.8828 1.9251 sec/batch\n",
      "Nearest to it: seemed, only, bundled, said, but, edif, the, spoon,\n",
      "Nearest to four: five, two, one, eight, seven, six, three, zero,\n",
      "Nearest to called: smp, inner, such, sent, kiswahili, multiplicity, sultanate, unity,\n",
      "Nearest to th: century, mtsho, manzikert, st, nd, waxed, six, rd,\n",
      "Nearest to years: female, year, days, age, zero, due, five, ago,\n",
      "Nearest to were: was, previously, in, symbionts, ostia, ghettos, excluded, those,\n",
      "Nearest to their: they, either, the, with, multiple, most, metron, fact,\n",
      "Nearest to other: are, as, usually, such, use, to, number, many,\n",
      "Nearest to file: files, formats, finalised, delete, nostra, encode, nix, carrel,\n",
      "Nearest to construction: motorway, design, engineering, building, southside, dam, ieoh, talc,\n",
      "Nearest to except: introduces, seiy, masse, omitted, councilor, qsort, proviso, dek,\n",
      "Nearest to shows: show, borkou, modules, pontificia, according, aired, cfsp, scrabble,\n",
      "Nearest to articles: revise, takla, oren, expiration, publications, merino, comprehensive, dess,\n",
      "Nearest to grand: lithuanian, vilnius, tempelhof, freemasonic, prix, ostpolitik, chiefs, polis,\n",
      "Nearest to units: makeup, housing, residing, mi, quicksand, unit, density, conifer,\n",
      "Nearest to resources: tempura, notebooks, ore, extremes, envoy, safeguarding, arable, assesses,\n",
      "Epoch 8/10 Iteration: 33100 Avg. Training loss: 3.8245 1.9525 sec/batch\n",
      "Epoch 8/10 Iteration: 33200 Avg. Training loss: 3.8825 1.9162 sec/batch\n",
      "Epoch 8/10 Iteration: 33300 Avg. Training loss: 3.9042 1.9134 sec/batch\n",
      "Epoch 8/10 Iteration: 33400 Avg. Training loss: 3.9127 1.9267 sec/batch\n",
      "Epoch 8/10 Iteration: 33500 Avg. Training loss: 3.8757 1.9251 sec/batch\n",
      "Epoch 8/10 Iteration: 33600 Avg. Training loss: 3.8136 1.9255 sec/batch\n",
      "Epoch 8/10 Iteration: 33700 Avg. Training loss: 3.8643 1.9195 sec/batch\n",
      "Epoch 8/10 Iteration: 33800 Avg. Training loss: 3.8077 1.9125 sec/batch\n",
      "Epoch 8/10 Iteration: 33900 Avg. Training loss: 3.8798 1.9170 sec/batch\n",
      "Epoch 8/10 Iteration: 34000 Avg. Training loss: 3.8807 1.9160 sec/batch\n",
      "Nearest to it: only, seemed, bundled, the, as, but, edif, since,\n",
      "Nearest to four: five, two, one, eight, six, seven, three, zero,\n",
      "Nearest to called: such, smp, forming, unity, inner, nucleoside, which, sent,\n",
      "Nearest to th: century, mtsho, st, waxed, nd, manzikert, designated, rd,\n",
      "Nearest to years: female, year, days, zero, age, five, due, two,\n",
      "Nearest to were: was, last, previously, excluded, ostia, those, in, ghettos,\n",
      "Nearest to their: they, the, either, with, most, to, for, multiple,\n",
      "Nearest to other: are, as, use, usually, such, to, be, in,\n",
      "Nearest to file: files, formats, delete, encode, carrel, nostra, finalised, nix,\n",
      "Nearest to construction: design, motorway, building, engineering, southside, ieoh, dam, appreciably,\n",
      "Nearest to except: introduces, seiy, omitted, pieces, quer, ectocervix, lamp, kuni,\n",
      "Nearest to shows: show, borkou, aired, modules, pontificia, according, cfsp, schlei,\n",
      "Nearest to articles: revise, takla, oren, expiration, publications, merino, balto, information,\n",
      "Nearest to grand: lithuanian, tempelhof, vilnius, ostpolitik, surfing, prix, freemasonic, polis,\n",
      "Nearest to units: makeup, housing, quicksand, residing, unit, mi, conifer, density,\n",
      "Nearest to resources: tempura, notebooks, ore, extremes, envoy, assesses, arable, safeguarding,\n",
      "Epoch 8/10 Iteration: 34100 Avg. Training loss: 3.8440 1.9456 sec/batch\n",
      "Epoch 8/10 Iteration: 34200 Avg. Training loss: 3.8444 1.9170 sec/batch\n",
      "Epoch 8/10 Iteration: 34300 Avg. Training loss: 3.8782 1.9134 sec/batch\n",
      "Epoch 8/10 Iteration: 34400 Avg. Training loss: 3.9085 1.9284 sec/batch\n",
      "Epoch 8/10 Iteration: 34500 Avg. Training loss: 3.8420 1.9264 sec/batch\n",
      "Epoch 8/10 Iteration: 34600 Avg. Training loss: 3.8758 1.9168 sec/batch\n",
      "Epoch 8/10 Iteration: 34700 Avg. Training loss: 3.8714 1.9145 sec/batch\n",
      "Epoch 8/10 Iteration: 34800 Avg. Training loss: 3.8994 1.9273 sec/batch\n",
      "Epoch 8/10 Iteration: 34900 Avg. Training loss: 3.8850 1.9139 sec/batch\n",
      "Epoch 8/10 Iteration: 35000 Avg. Training loss: 3.9182 1.9190 sec/batch\n",
      "Nearest to it: only, seemed, since, but, edif, the, said, bundled,\n",
      "Nearest to four: five, two, one, eight, six, seven, three, zero,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest to called: smp, such, unity, known, multiplicity, forming, sent, quebec,\n",
      "Nearest to th: century, mtsho, waxed, st, nd, manzikert, bealtaine, stoicism,\n",
      "Nearest to years: female, year, days, age, zero, due, five, male,\n",
      "Nearest to were: was, being, previously, last, excluded, in, ostia, machines,\n",
      "Nearest to their: they, either, the, multiple, with, most, for, more,\n",
      "Nearest to other: are, as, use, usually, in, to, such, be,\n",
      "Nearest to file: files, encode, delete, finalised, carrel, nostra, admixture, nix,\n",
      "Nearest to construction: design, motorway, southside, engineering, building, ieoh, dam, kimberley,\n",
      "Nearest to except: introduces, omitted, unaccompanied, qsort, quer, dek, proviso, councilor,\n",
      "Nearest to shows: show, borkou, aired, pontificia, modules, schlei, according, distinguished,\n",
      "Nearest to articles: revise, oren, takla, expiration, publications, online, merino, quotes,\n",
      "Nearest to grand: lithuanian, prix, surfing, vilnius, destabilizing, tempelhof, ostpolitik, freemasonic,\n",
      "Nearest to units: makeup, housing, residing, mi, quicksand, unit, density, conifer,\n",
      "Nearest to resources: tempura, notebooks, ore, envoy, extremes, assesses, safeguarding, arable,\n",
      "Epoch 8/10 Iteration: 35100 Avg. Training loss: 3.8774 1.9530 sec/batch\n",
      "Epoch 8/10 Iteration: 35200 Avg. Training loss: 3.8943 1.9416 sec/batch\n",
      "Epoch 8/10 Iteration: 35300 Avg. Training loss: 3.8993 1.9332 sec/batch\n",
      "Epoch 8/10 Iteration: 35400 Avg. Training loss: 3.9089 1.9446 sec/batch\n",
      "Epoch 8/10 Iteration: 35500 Avg. Training loss: 3.9032 1.9209 sec/batch\n",
      "Epoch 8/10 Iteration: 35600 Avg. Training loss: 3.8798 1.9246 sec/batch\n",
      "Epoch 8/10 Iteration: 35700 Avg. Training loss: 3.8370 1.9194 sec/batch\n",
      "Epoch 8/10 Iteration: 35800 Avg. Training loss: 3.8710 1.9206 sec/batch\n",
      "Epoch 8/10 Iteration: 35900 Avg. Training loss: 3.9234 1.9370 sec/batch\n",
      "Epoch 8/10 Iteration: 36000 Avg. Training loss: 3.8388 1.9331 sec/batch\n",
      "Nearest to it: only, seemed, edif, bundled, said, since, but, respecting,\n",
      "Nearest to four: five, one, eight, two, seven, three, six, zero,\n",
      "Nearest to called: smp, sent, such, unity, known, pashtunistan, kiswahili, plus,\n",
      "Nearest to th: century, st, mtsho, waxed, nd, manzikert, six, rd,\n",
      "Nearest to years: days, year, female, age, due, months, ago, zero,\n",
      "Nearest to were: previously, in, was, last, being, ghettos, excluded, ostia,\n",
      "Nearest to their: they, either, the, with, multiple, metron, quadi, sharman,\n",
      "Nearest to other: are, as, use, such, usually, number, to, in,\n",
      "Nearest to file: files, encode, finalised, nostra, delete, formats, carrel, admixture,\n",
      "Nearest to construction: southside, motorway, ieoh, dam, building, engineering, design, constructed,\n",
      "Nearest to except: introduces, unaccompanied, omitted, dek, quer, councilor, transformational, proviso,\n",
      "Nearest to shows: show, borkou, aired, modules, pontificia, according, schlei, cfsp,\n",
      "Nearest to articles: revise, takla, expiration, oren, publications, merino, quotes, page,\n",
      "Nearest to grand: lithuanian, prix, vilnius, tempelhof, surfing, freemasonic, ostpolitik, roddick,\n",
      "Nearest to units: makeup, housing, unit, mi, residing, quicksand, conifer, density,\n",
      "Nearest to resources: tempura, notebooks, ore, extremes, envoy, arable, safeguarding, environmental,\n",
      "Epoch 8/10 Iteration: 36100 Avg. Training loss: 3.9753 1.9492 sec/batch\n",
      "Epoch 8/10 Iteration: 36200 Avg. Training loss: 3.9539 1.9220 sec/batch\n",
      "Epoch 8/10 Iteration: 36300 Avg. Training loss: 3.8917 1.9203 sec/batch\n",
      "Epoch 8/10 Iteration: 36400 Avg. Training loss: 3.8037 1.9126 sec/batch\n",
      "Epoch 8/10 Iteration: 36500 Avg. Training loss: 3.8340 1.9122 sec/batch\n",
      "Epoch 8/10 Iteration: 36600 Avg. Training loss: 3.8284 1.9274 sec/batch\n",
      "Epoch 8/10 Iteration: 36700 Avg. Training loss: 3.7978 1.9307 sec/batch\n",
      "Epoch 8/10 Iteration: 36800 Avg. Training loss: 3.9001 1.9226 sec/batch\n",
      "Epoch 8/10 Iteration: 36900 Avg. Training loss: 3.8832 1.9580 sec/batch\n",
      "Epoch 8/10 Iteration: 37000 Avg. Training loss: 3.8976 1.9208 sec/batch\n",
      "Nearest to it: seemed, only, edif, said, bundled, but, since, that,\n",
      "Nearest to four: five, two, one, eight, three, seven, six, zero,\n",
      "Nearest to called: smp, inner, such, forming, sent, unity, kiswahili, multiplicity,\n",
      "Nearest to th: century, mtsho, st, waxed, nd, manzikert, six, stoicism,\n",
      "Nearest to years: female, year, days, age, zero, five, due, male,\n",
      "Nearest to were: in, was, previously, ghettos, various, use, however, epidemic,\n",
      "Nearest to their: they, multiple, either, with, the, most, motorcyclists, sharman,\n",
      "Nearest to other: are, as, such, use, usually, number, to, many,\n",
      "Nearest to file: files, encode, finalised, formats, delete, nix, nostra, carrel,\n",
      "Nearest to construction: dam, southside, ieoh, motorway, constructed, design, building, engineering,\n",
      "Nearest to except: introduces, unaccompanied, omitted, quer, dek, councilor, qsort, osu,\n",
      "Nearest to shows: show, borkou, aired, pontificia, modules, according, wedding, schlei,\n",
      "Nearest to articles: revise, oren, takla, expiration, publications, dess, merino, balto,\n",
      "Nearest to grand: lithuanian, vilnius, prix, tempelhof, ostpolitik, chiefs, surfing, destabilizing,\n",
      "Nearest to units: makeup, housing, unit, mi, residing, quicksand, conifer, density,\n",
      "Nearest to resources: tempura, notebooks, ore, extremes, envoy, arable, safeguarding, assesses,\n",
      "Epoch 9/10 Iteration: 37100 Avg. Training loss: 3.8891 1.6091 sec/batch\n",
      "Epoch 9/10 Iteration: 37200 Avg. Training loss: 3.8531 2.1796 sec/batch\n",
      "Epoch 9/10 Iteration: 37300 Avg. Training loss: 3.8379 1.9273 sec/batch\n",
      "Epoch 9/10 Iteration: 37400 Avg. Training loss: 3.9008 1.8978 sec/batch\n",
      "Epoch 9/10 Iteration: 37500 Avg. Training loss: 3.8135 1.8973 sec/batch\n",
      "Epoch 9/10 Iteration: 37600 Avg. Training loss: 3.8629 1.8969 sec/batch\n",
      "Epoch 9/10 Iteration: 37700 Avg. Training loss: 3.7872 1.8978 sec/batch\n",
      "Epoch 9/10 Iteration: 37800 Avg. Training loss: 3.8969 1.9380 sec/batch\n",
      "Epoch 9/10 Iteration: 37900 Avg. Training loss: 3.8486 1.8929 sec/batch\n",
      "Epoch 9/10 Iteration: 38000 Avg. Training loss: 3.8702 1.9270 sec/batch\n",
      "Nearest to it: seemed, only, bundled, but, said, spoon, edif, violently,\n",
      "Nearest to four: five, two, one, eight, three, six, seven, zero,\n",
      "Nearest to called: smp, forming, such, inner, which, unity, plus, known,\n",
      "Nearest to th: century, mtsho, st, nd, waxed, manzikert, six, rd,\n",
      "Nearest to years: female, year, days, zero, age, two, five, due,\n",
      "Nearest to were: was, in, previously, later, however, last, and, ghettos,\n",
      "Nearest to their: they, with, either, the, multiple, to, most, fact,\n",
      "Nearest to other: are, as, such, use, usually, number, be, these,\n",
      "Nearest to file: files, encode, finalised, delete, formats, nix, nostra, carrel,\n",
      "Nearest to construction: building, ieoh, southside, motorway, design, dam, constructed, engineering,\n",
      "Nearest to except: introduces, quer, unaccompanied, omitted, kuni, ectocervix, osu, negro,\n",
      "Nearest to shows: show, borkou, aired, modules, according, pontificia, wedding, schlei,\n",
      "Nearest to articles: revise, oren, publications, takla, expiration, dess, information, page,\n",
      "Nearest to grand: lithuanian, prix, vilnius, tempelhof, ostpolitik, surfing, polis, destabilizing,\n",
      "Nearest to units: makeup, housing, mi, residing, unit, quicksand, conifer, density,\n",
      "Nearest to resources: tempura, notebooks, ore, extremes, envoy, arable, safeguarding, assesses,\n",
      "Epoch 9/10 Iteration: 38100 Avg. Training loss: 3.8804 1.9074 sec/batch\n",
      "Epoch 9/10 Iteration: 38200 Avg. Training loss: 3.7219 1.8973 sec/batch\n",
      "Epoch 9/10 Iteration: 38300 Avg. Training loss: 3.8420 1.9256 sec/batch\n",
      "Epoch 9/10 Iteration: 38400 Avg. Training loss: 3.8265 1.8774 sec/batch\n",
      "Epoch 9/10 Iteration: 38500 Avg. Training loss: 3.7896 2.0283 sec/batch\n",
      "Epoch 9/10 Iteration: 38600 Avg. Training loss: 3.8705 2.0371 sec/batch\n",
      "Epoch 9/10 Iteration: 38700 Avg. Training loss: 3.8814 1.9114 sec/batch\n",
      "Epoch 9/10 Iteration: 38800 Avg. Training loss: 3.7858 1.9025 sec/batch\n",
      "Epoch 9/10 Iteration: 38900 Avg. Training loss: 3.8461 1.8997 sec/batch\n",
      "Epoch 9/10 Iteration: 39000 Avg. Training loss: 3.9068 1.9216 sec/batch\n",
      "Nearest to it: seemed, only, but, bundled, edif, to, as, since,\n",
      "Nearest to four: five, two, one, eight, three, seven, six, zero,\n",
      "Nearest to called: which, such, forming, known, smp, inner, sent, the,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest to th: century, st, mtsho, nd, waxed, manzikert, rd, six,\n",
      "Nearest to years: female, year, days, age, zero, five, two, ago,\n",
      "Nearest to were: was, previously, later, in, many, however, various, last,\n",
      "Nearest to their: they, the, with, either, most, to, from, multiple,\n",
      "Nearest to other: are, as, such, use, and, be, usually, these,\n",
      "Nearest to file: files, encode, delete, finalised, nix, formats, carrel, nostra,\n",
      "Nearest to construction: building, ieoh, motorway, design, dam, southside, engineering, shea,\n",
      "Nearest to except: introduces, unaccompanied, quer, omitted, ectocervix, qsort, kuni, replenished,\n",
      "Nearest to shows: show, aired, borkou, modules, wedding, according, special, pontificia,\n",
      "Nearest to articles: revise, publications, oren, expiration, dess, takla, information, page,\n",
      "Nearest to grand: lithuanian, prix, vilnius, tempelhof, freemasonic, surfing, ostpolitik, destabilizing,\n",
      "Nearest to units: makeup, housing, unit, mi, residing, quicksand, conifer, density,\n",
      "Nearest to resources: tempura, notebooks, ore, extremes, envoy, arable, safeguarding, ennedi,\n",
      "Epoch 9/10 Iteration: 39100 Avg. Training loss: 3.8594 1.9759 sec/batch\n",
      "Epoch 9/10 Iteration: 39200 Avg. Training loss: 3.8402 1.9178 sec/batch\n",
      "Epoch 9/10 Iteration: 39300 Avg. Training loss: 3.8656 1.8916 sec/batch\n",
      "Epoch 9/10 Iteration: 39400 Avg. Training loss: 3.8564 1.8972 sec/batch\n",
      "Epoch 9/10 Iteration: 39500 Avg. Training loss: 3.8528 1.9097 sec/batch\n",
      "Epoch 9/10 Iteration: 39600 Avg. Training loss: 3.8887 1.9462 sec/batch\n",
      "Epoch 9/10 Iteration: 39700 Avg. Training loss: 3.8617 1.9051 sec/batch\n",
      "Epoch 9/10 Iteration: 39800 Avg. Training loss: 3.8434 1.9003 sec/batch\n",
      "Epoch 9/10 Iteration: 39900 Avg. Training loss: 3.8718 1.9046 sec/batch\n",
      "Epoch 9/10 Iteration: 40000 Avg. Training loss: 3.8715 1.9254 sec/batch\n",
      "Nearest to it: seemed, only, but, bundled, to, since, edif, said,\n",
      "Nearest to four: five, two, one, three, eight, seven, six, zero,\n",
      "Nearest to called: which, known, smp, forming, such, sent, unity, along,\n",
      "Nearest to th: century, mtsho, st, waxed, nd, manzikert, six, rd,\n",
      "Nearest to years: female, year, zero, age, days, five, two, male,\n",
      "Nearest to were: was, in, however, various, many, excluded, previously, later,\n",
      "Nearest to their: they, either, multiple, the, most, for, with, are,\n",
      "Nearest to other: as, are, such, use, and, many, usually, these,\n",
      "Nearest to file: files, encode, formats, nix, finalised, delete, nostra, reboot,\n",
      "Nearest to construction: design, ieoh, building, motorway, dam, southside, constructed, engineering,\n",
      "Nearest to except: introduces, unaccompanied, quer, omitted, dek, kuni, councilor, guam,\n",
      "Nearest to shows: show, aired, borkou, modules, according, wedding, special, pontificia,\n",
      "Nearest to articles: revise, publications, information, online, takla, oren, expiration, page,\n",
      "Nearest to grand: lithuanian, prix, vilnius, freemasonic, tempelhof, surfing, destabilizing, leverage,\n",
      "Nearest to units: makeup, housing, mi, residing, unit, quicksand, density, conifer,\n",
      "Nearest to resources: tempura, notebooks, ore, extremes, envoy, safeguarding, arable, ennedi,\n",
      "Epoch 9/10 Iteration: 40100 Avg. Training loss: 3.8645 1.9248 sec/batch\n",
      "Epoch 9/10 Iteration: 40200 Avg. Training loss: 3.8606 1.8739 sec/batch\n",
      "Epoch 9/10 Iteration: 40300 Avg. Training loss: 3.8292 1.8700 sec/batch\n",
      "Epoch 9/10 Iteration: 40400 Avg. Training loss: 3.8350 1.8727 sec/batch\n",
      "Epoch 9/10 Iteration: 40500 Avg. Training loss: 3.8894 1.8887 sec/batch\n",
      "Epoch 9/10 Iteration: 40600 Avg. Training loss: 3.8465 1.8945 sec/batch\n",
      "Epoch 9/10 Iteration: 40700 Avg. Training loss: 3.9557 1.9125 sec/batch\n",
      "Epoch 9/10 Iteration: 40800 Avg. Training loss: 3.8871 1.8891 sec/batch\n",
      "Epoch 9/10 Iteration: 40900 Avg. Training loss: 3.9168 1.8849 sec/batch\n",
      "Epoch 9/10 Iteration: 41000 Avg. Training loss: 3.8350 1.8940 sec/batch\n",
      "Nearest to it: seemed, only, but, since, bundled, to, as, part,\n",
      "Nearest to four: five, two, one, three, eight, six, seven, zero,\n",
      "Nearest to called: smp, known, such, sent, profiler, unity, plus, which,\n",
      "Nearest to th: century, st, mtsho, nd, waxed, six, manzikert, rd,\n",
      "Nearest to years: female, year, zero, days, age, five, two, due,\n",
      "Nearest to were: was, many, later, in, previously, various, however, and,\n",
      "Nearest to their: they, with, multiple, the, bitnet, to, either, fact,\n",
      "Nearest to other: as, use, such, are, and, usually, be, many,\n",
      "Nearest to file: files, encode, finalised, nix, reboot, formats, nostra, admixture,\n",
      "Nearest to construction: dam, constructed, ieoh, motorway, engineering, design, building, southside,\n",
      "Nearest to except: introduces, unaccompanied, quer, omitted, councilor, dek, kuni, guam,\n",
      "Nearest to shows: show, aired, borkou, according, wedding, pontificia, modules, hiatus,\n",
      "Nearest to articles: revise, publications, expiration, page, article, information, dess, online,\n",
      "Nearest to grand: lithuanian, prix, tempelhof, vilnius, freemasonic, roddick, chiefs, ostpolitik,\n",
      "Nearest to units: makeup, housing, unit, mi, residing, quicksand, density, conifer,\n",
      "Nearest to resources: extremes, tempura, ore, arable, notebooks, erosion, safeguarding, ennedi,\n",
      "Epoch 9/10 Iteration: 41100 Avg. Training loss: 3.8083 1.8912 sec/batch\n",
      "Epoch 9/10 Iteration: 41200 Avg. Training loss: 3.8616 1.8737 sec/batch\n",
      "Epoch 9/10 Iteration: 41300 Avg. Training loss: 3.7693 1.8850 sec/batch\n",
      "Epoch 9/10 Iteration: 41400 Avg. Training loss: 3.9071 1.8856 sec/batch\n",
      "Epoch 9/10 Iteration: 41500 Avg. Training loss: 3.8629 1.8830 sec/batch\n",
      "Epoch 9/10 Iteration: 41600 Avg. Training loss: 3.8476 1.8794 sec/batch\n",
      "Epoch 10/10 Iteration: 41700 Avg. Training loss: 3.9062 0.9110 sec/batch\n",
      "Epoch 10/10 Iteration: 41800 Avg. Training loss: 3.8312 1.8843 sec/batch\n",
      "Epoch 10/10 Iteration: 41900 Avg. Training loss: 3.8279 1.9634 sec/batch\n",
      "Epoch 10/10 Iteration: 42000 Avg. Training loss: 3.8208 1.9231 sec/batch\n",
      "Nearest to it: but, seemed, only, to, said, the, as, that,\n",
      "Nearest to four: five, two, one, eight, seven, three, six, zero,\n",
      "Nearest to called: smp, known, sent, the, which, forming, along, such,\n",
      "Nearest to th: century, st, mtsho, nd, waxed, six, five, manzikert,\n",
      "Nearest to years: female, year, days, zero, age, five, two, male,\n",
      "Nearest to were: in, was, later, various, many, previously, though, however,\n",
      "Nearest to their: they, to, the, with, for, multiple, fact, from,\n",
      "Nearest to other: as, such, are, use, many, usually, and, be,\n",
      "Nearest to file: files, encode, finalised, nix, carrel, formats, delete, nostra,\n",
      "Nearest to construction: dam, constructed, ieoh, motorway, building, design, engineering, southside,\n",
      "Nearest to except: introduces, unaccompanied, quer, councilor, omitted, dek, kuni, qsort,\n",
      "Nearest to shows: show, aired, borkou, modules, wedding, according, may, tv,\n",
      "Nearest to articles: revise, expiration, publications, dess, page, ratification, article, takla,\n",
      "Nearest to grand: lithuanian, prix, tempelhof, vilnius, freemasonic, surfing, chiefs, ostpolitik,\n",
      "Nearest to units: makeup, housing, unit, mi, residing, quicksand, density, gulag,\n",
      "Nearest to resources: tempura, notebooks, extremes, safeguarding, arable, ore, envoy, society,\n",
      "Epoch 10/10 Iteration: 42100 Avg. Training loss: 3.8387 1.9204 sec/batch\n",
      "Epoch 10/10 Iteration: 42200 Avg. Training loss: 3.7943 1.9049 sec/batch\n",
      "Epoch 10/10 Iteration: 42300 Avg. Training loss: 3.8428 1.9140 sec/batch\n",
      "Epoch 10/10 Iteration: 42400 Avg. Training loss: 3.7810 1.9552 sec/batch\n",
      "Epoch 10/10 Iteration: 42500 Avg. Training loss: 3.8657 2.0257 sec/batch\n",
      "Epoch 10/10 Iteration: 42600 Avg. Training loss: 3.8524 1.9455 sec/batch\n",
      "Epoch 10/10 Iteration: 42700 Avg. Training loss: 3.8723 1.9757 sec/batch\n",
      "Epoch 10/10 Iteration: 42800 Avg. Training loss: 3.7229 1.9636 sec/batch\n",
      "Epoch 10/10 Iteration: 42900 Avg. Training loss: 3.7894 1.9381 sec/batch\n",
      "Epoch 10/10 Iteration: 43000 Avg. Training loss: 3.8166 1.9080 sec/batch\n",
      "Nearest to it: but, only, to, as, the, seemed, by, not,\n",
      "Nearest to four: five, two, one, three, eight, six, seven, zero,\n",
      "Nearest to called: which, known, such, the, forming, a, of, smp,\n",
      "Nearest to th: century, mtsho, st, nd, waxed, six, manzikert, especially,\n",
      "Nearest to years: female, year, zero, days, age, five, two, male,\n",
      "Nearest to were: was, however, later, various, previously, many, in, fairey,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest to their: they, the, for, to, with, from, multiple, either,\n",
      "Nearest to other: as, are, such, use, and, many, to, with,\n",
      "Nearest to file: files, encode, delete, finalised, carrel, nix, nostra, formats,\n",
      "Nearest to construction: building, dam, constructed, ieoh, motorway, design, engineering, talc,\n",
      "Nearest to except: introduces, quer, unaccompanied, omitted, councilor, ectocervix, kuni, dek,\n",
      "Nearest to shows: show, borkou, aired, according, wedding, modules, pontificia, special,\n",
      "Nearest to articles: publications, revise, page, dess, online, information, oren, expiration,\n",
      "Nearest to grand: lithuanian, prix, tempelhof, vilnius, freemasonic, destabilizing, surfing, ostpolitik,\n",
      "Nearest to units: makeup, housing, mi, unit, residing, quicksand, conifer, density,\n",
      "Nearest to resources: tempura, notebooks, extremes, arable, ore, society, cacao, envoy,\n",
      "Epoch 10/10 Iteration: 43100 Avg. Training loss: 3.7719 1.9606 sec/batch\n",
      "Epoch 10/10 Iteration: 43200 Avg. Training loss: 3.8361 1.9692 sec/batch\n",
      "Epoch 10/10 Iteration: 43300 Avg. Training loss: 3.8555 1.9855 sec/batch\n",
      "Epoch 10/10 Iteration: 43400 Avg. Training loss: 3.8361 1.9350 sec/batch\n",
      "Epoch 10/10 Iteration: 43500 Avg. Training loss: 3.8083 1.9079 sec/batch\n",
      "Epoch 10/10 Iteration: 43600 Avg. Training loss: 3.9080 1.8892 sec/batch\n",
      "Epoch 10/10 Iteration: 43700 Avg. Training loss: 3.8412 1.8878 sec/batch\n",
      "Epoch 10/10 Iteration: 43800 Avg. Training loss: 3.8135 1.8964 sec/batch\n",
      "Epoch 10/10 Iteration: 43900 Avg. Training loss: 3.7964 1.8918 sec/batch\n",
      "Epoch 10/10 Iteration: 44000 Avg. Training loss: 3.8516 1.8816 sec/batch\n",
      "Nearest to it: but, only, to, that, seemed, the, not, bundled,\n",
      "Nearest to four: five, two, one, three, eight, six, seven, zero,\n",
      "Nearest to called: which, known, the, along, such, forming, sent, smp,\n",
      "Nearest to th: century, st, nd, mtsho, waxed, six, known, five,\n",
      "Nearest to years: female, days, year, zero, age, five, two, male,\n",
      "Nearest to were: was, however, previously, various, many, in, though, those,\n",
      "Nearest to their: they, the, to, for, are, with, many, and,\n",
      "Nearest to other: are, as, use, and, such, in, be, many,\n",
      "Nearest to file: files, delete, encode, finalised, admixture, carrel, nostra, magdalene,\n",
      "Nearest to construction: building, dam, motorway, ieoh, constructed, design, southside, shea,\n",
      "Nearest to except: introduces, quer, councilor, unaccompanied, obeyed, omitted, ectocervix, transformational,\n",
      "Nearest to shows: show, aired, borkou, according, wedding, modules, pontificia, special,\n",
      "Nearest to articles: publications, dess, revise, page, expiration, oren, article, information,\n",
      "Nearest to grand: lithuanian, prix, freemasonic, vilnius, tempelhof, destabilizing, ostpolitik, today,\n",
      "Nearest to units: makeup, unit, mi, housing, residing, quicksand, density, conifer,\n",
      "Nearest to resources: tempura, notebooks, extremes, ore, arable, modeling, envoy, society,\n",
      "Epoch 10/10 Iteration: 44100 Avg. Training loss: 3.8637 1.9306 sec/batch\n",
      "Epoch 10/10 Iteration: 44200 Avg. Training loss: 3.8412 1.9705 sec/batch\n",
      "Epoch 10/10 Iteration: 44300 Avg. Training loss: 3.8230 2.1004 sec/batch\n",
      "Epoch 10/10 Iteration: 44400 Avg. Training loss: 3.8244 2.1905 sec/batch\n",
      "Epoch 10/10 Iteration: 44500 Avg. Training loss: 3.8754 1.9513 sec/batch\n",
      "Epoch 10/10 Iteration: 44600 Avg. Training loss: 3.8319 1.9487 sec/batch\n",
      "Epoch 10/10 Iteration: 44700 Avg. Training loss: 3.8440 1.9405 sec/batch\n",
      "Epoch 10/10 Iteration: 44800 Avg. Training loss: 3.8427 1.9938 sec/batch\n",
      "Epoch 10/10 Iteration: 44900 Avg. Training loss: 3.8284 2.3339 sec/batch\n",
      "Epoch 10/10 Iteration: 45000 Avg. Training loss: 3.8320 2.2474 sec/batch\n",
      "Nearest to it: but, only, to, the, since, seemed, that, bundled,\n",
      "Nearest to four: five, one, two, three, eight, six, seven, zero,\n",
      "Nearest to called: which, the, known, such, a, smp, profiler, referred,\n",
      "Nearest to th: century, st, nd, waxed, known, mtsho, centuries, six,\n",
      "Nearest to years: female, zero, days, age, year, five, two, due,\n",
      "Nearest to were: many, however, was, in, various, been, previously, for,\n",
      "Nearest to their: they, the, to, for, are, multiple, with, only,\n",
      "Nearest to other: as, are, such, use, and, many, be, in,\n",
      "Nearest to file: files, finalised, delete, encode, formats, nix, nostra, carrel,\n",
      "Nearest to construction: dam, building, constructed, motorway, ieoh, design, shea, southside,\n",
      "Nearest to except: introduces, unaccompanied, quer, councilor, omitted, transformational, ectocervix, kuni,\n",
      "Nearest to shows: show, borkou, according, modules, aired, distinguished, schlei, vladimir,\n",
      "Nearest to articles: publications, article, dess, revise, information, online, page, expiration,\n",
      "Nearest to grand: lithuanian, freemasonic, prix, vilnius, tempelhof, gygax, ostpolitik, destabilizing,\n",
      "Nearest to units: makeup, unit, mi, housing, residing, quicksand, conifer, density,\n",
      "Nearest to resources: tempura, notebooks, ore, extremes, arable, cacao, envoy, safeguarding,\n",
      "Epoch 10/10 Iteration: 45100 Avg. Training loss: 3.8406 2.0334 sec/batch\n",
      "Epoch 10/10 Iteration: 45200 Avg. Training loss: 3.8261 2.1847 sec/batch\n",
      "Epoch 10/10 Iteration: 45300 Avg. Training loss: 3.9178 2.0829 sec/batch\n",
      "Epoch 10/10 Iteration: 45400 Avg. Training loss: 3.9026 1.9785 sec/batch\n",
      "Epoch 10/10 Iteration: 45500 Avg. Training loss: 3.9052 2.4040 sec/batch\n",
      "Epoch 10/10 Iteration: 45600 Avg. Training loss: 3.8677 2.1499 sec/batch\n",
      "Epoch 10/10 Iteration: 45700 Avg. Training loss: 3.7786 2.0183 sec/batch\n",
      "Epoch 10/10 Iteration: 45800 Avg. Training loss: 3.8218 1.9777 sec/batch\n",
      "Epoch 10/10 Iteration: 45900 Avg. Training loss: 3.7601 1.9838 sec/batch\n",
      "Epoch 10/10 Iteration: 46000 Avg. Training loss: 3.8653 1.9865 sec/batch\n",
      "Nearest to it: but, to, only, not, seemed, that, the, said,\n",
      "Nearest to four: five, two, one, three, eight, seven, zero, six,\n",
      "Nearest to called: which, such, known, a, the, smp, along, profiler,\n",
      "Nearest to th: century, nd, st, waxed, mtsho, known, manzikert, six,\n",
      "Nearest to years: female, zero, year, five, days, age, two, male,\n",
      "Nearest to were: many, in, however, previously, various, was, later, use,\n",
      "Nearest to their: they, the, for, to, multiple, with, fact, are,\n",
      "Nearest to other: as, such, and, many, are, use, in, with,\n",
      "Nearest to file: files, delete, formats, finalised, nostra, encode, nix, admixture,\n",
      "Nearest to construction: dam, constructed, building, motorway, ieoh, shea, design, talc,\n",
      "Nearest to except: introduces, unaccompanied, quer, councilor, omitted, ectocervix, transformational, kuni,\n",
      "Nearest to shows: show, aired, borkou, pontificia, modules, tv, wedding, may,\n",
      "Nearest to articles: revise, publications, dess, article, page, online, oren, information,\n",
      "Nearest to grand: lithuanian, tempelhof, vilnius, freemasonic, prix, ostpolitik, roddick, gygax,\n",
      "Nearest to units: unit, makeup, housing, mi, residing, quicksand, density, conifer,\n",
      "Nearest to resources: tempura, extremes, arable, ore, notebooks, envoy, including, society,\n",
      "Epoch 10/10 Iteration: 46100 Avg. Training loss: 3.8596 2.0126 sec/batch\n",
      "Epoch 10/10 Iteration: 46200 Avg. Training loss: 3.8154 1.9877 sec/batch\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 1000\n",
    "window_size = 10\n",
    "\n",
    "with train_graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    iteration = 1\n",
    "    loss = 0\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        batches = get_batches(train_words, batch_size, window_size)\n",
    "        start = time.time()\n",
    "        for x, y in batches:\n",
    "            \n",
    "            feed = {inputs: x,\n",
    "                    labels: np.array(y)[:, None]}\n",
    "            train_loss, _ = sess.run([cost, optimizer], feed_dict=feed)\n",
    "            \n",
    "            loss += train_loss\n",
    "            \n",
    "            if iteration % 100 == 0: \n",
    "                end = time.time()\n",
    "                print(\"Epoch {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Avg. Training loss: {:.4f}\".format(loss/100),\n",
    "                      \"{:.4f} sec/batch\".format((end-start)/100))\n",
    "                loss = 0\n",
    "                start = time.time()\n",
    "            \n",
    "            if iteration % 1000 == 0:\n",
    "                # note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "                sim = similarity.eval()\n",
    "                for i in range(valid_size):\n",
    "                    valid_word = int_to_vocab[valid_examples[i]]\n",
    "                    top_k = 8 # number of nearest neighbors\n",
    "                    nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
    "                    log = 'Nearest to %s:' % valid_word\n",
    "                    for k in range(top_k):\n",
    "                        close_word = int_to_vocab[nearest[k]]\n",
    "                        log = '%s %s,' % (log, close_word)\n",
    "                    print(log)\n",
    "            \n",
    "            iteration += 1\n",
    "    save_path = saver.save(sess, \"checkpoints/text8.ckpt\")\n",
    "    embed_mat = sess.run(normalized_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Очень долго обучается, так что пока как-то так (("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with train_graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    embed_mat = sess.run(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viz_words = 500\n",
    "tsne = TSNE()\n",
    "embed_tsne = tsne.fit_transform(embed_mat[:viz_words, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 14))\n",
    "for idx in range(viz_words):\n",
    "    plt.scatter(*embed_tsne[idx, :], color='steelblue')\n",
    "    plt.annotate(int_to_vocab[idx], (embed_tsne[idx, 0], embed_tsne[idx, 1]), alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
