{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Орехова Дарья, 15ФПЛ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Exercise \n",
    "\n",
    "California Housing Data\n",
    "\n",
    "This data set contains information about all the block groups in California from the 1990 Census. In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. \n",
    "\n",
    "The task is to aproximate the median house value of each block from the values of the rest of the variables. \n",
    "\n",
    " It has been obtained from the LIACC repository. The original page where the data set can be found is: http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Features:\n",
    " \n",
    "* housingMedianAge: continuous. \n",
    "* totalRooms: continuous. \n",
    "* totalBedrooms: continuous. \n",
    "* population: continuous. \n",
    "* households: continuous. \n",
    "* medianIncome: continuous. \n",
    "* medianHouseValue: continuous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the cal_housing_clean.csv file with pandas. Separate it into a training (70%) and testing set(30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('California Housing data.csv')\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>MedInc</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  HouseAge  AveRooms  AveBedrms  Population  AveOccup  MedInc  \\\n",
       "0           0      41.0  6.984127   1.023810       322.0  2.555556  8.3252   \n",
       "1           1      21.0  6.238137   0.971880      2401.0  2.109842  8.3014   \n",
       "2           2      52.0  8.288136   1.073446       496.0  2.802260  7.2574   \n",
       "3           3      52.0  5.817352   1.073059       558.0  2.547945  5.6431   \n",
       "4           4      52.0  6.281853   1.081081       565.0  2.181467  3.8462   \n",
       "\n",
       "   Latitude  Longitude  medianHouseValue  \n",
       "0     37.88    -122.23             4.526  \n",
       "1     37.86    -122.22             3.585  \n",
       "2     37.85    -122.24             3.521  \n",
       "3     37.85    -122.25             3.413  \n",
       "4     37.85    -122.25             3.422  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>MedInc</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.600000</td>\n",
       "      <td>6.721921</td>\n",
       "      <td>1.044655</td>\n",
       "      <td>868.400000</td>\n",
       "      <td>2.439414</td>\n",
       "      <td>6.674660</td>\n",
       "      <td>37.858000</td>\n",
       "      <td>-122.238000</td>\n",
       "      <td>3.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.501852</td>\n",
       "      <td>0.970532</td>\n",
       "      <td>0.046619</td>\n",
       "      <td>862.336535</td>\n",
       "      <td>0.288132</td>\n",
       "      <td>1.921878</td>\n",
       "      <td>0.013038</td>\n",
       "      <td>0.013038</td>\n",
       "      <td>0.470897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>3.846200</td>\n",
       "      <td>37.850000</td>\n",
       "      <td>-122.250000</td>\n",
       "      <td>3.413000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>496.000000</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>5.643100</td>\n",
       "      <td>37.850000</td>\n",
       "      <td>-122.250000</td>\n",
       "      <td>3.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>7.257400</td>\n",
       "      <td>37.850000</td>\n",
       "      <td>-122.240000</td>\n",
       "      <td>3.521000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>565.000000</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>8.301400</td>\n",
       "      <td>37.860000</td>\n",
       "      <td>-122.230000</td>\n",
       "      <td>3.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>2401.000000</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>8.325200</td>\n",
       "      <td>37.880000</td>\n",
       "      <td>-122.220000</td>\n",
       "      <td>4.526000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        HouseAge  AveRooms  AveBedrms   Population  AveOccup    MedInc  \\\n",
       "count   5.000000  5.000000   5.000000     5.000000  5.000000  5.000000   \n",
       "mean   43.600000  6.721921   1.044655   868.400000  2.439414  6.674660   \n",
       "std    13.501852  0.970532   0.046619   862.336535  0.288132  1.921878   \n",
       "min    21.000000  5.817352   0.971880   322.000000  2.109842  3.846200   \n",
       "25%    41.000000  6.238137   1.023810   496.000000  2.181467  5.643100   \n",
       "50%    52.000000  6.281853   1.073059   558.000000  2.547945  7.257400   \n",
       "75%    52.000000  6.984127   1.073446   565.000000  2.555556  8.301400   \n",
       "max    52.000000  8.288136   1.081081  2401.000000  2.802260  8.325200   \n",
       "\n",
       "        Latitude   Longitude  medianHouseValue  \n",
       "count   5.000000    5.000000          5.000000  \n",
       "mean   37.858000 -122.238000          3.693400  \n",
       "std     0.013038    0.013038          0.470897  \n",
       "min    37.850000 -122.250000          3.413000  \n",
       "25%    37.850000 -122.250000          3.422000  \n",
       "50%    37.850000 -122.240000          3.521000  \n",
       "75%    37.860000 -122.230000          3.585000  \n",
       "max    37.880000 -122.220000          4.526000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(labels='Unnamed: 0', inplace=True, axis=1)\n",
    "data.head().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_data = data['medianHouseValue']\n",
    "data.drop(labels=['medianHouseValue'], inplace=True, axis =1)\n",
    "x_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(x_data, y_data, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5748     2.387\n",
       "5592     1.711\n",
       "2110     0.554\n",
       "13901    0.696\n",
       "18425    2.131\n",
       "Name: medianHouseValue, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator. They should all be trated as continuous numeric_columns. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'MedInc',\n",
       "       'Latitude', 'Longitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data=X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(data=X_test_scaled, columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='HouseAge', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='AveRooms', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='AveBedrms', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Population', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='AveOccup', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='MedInc', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Longitude', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Latitude', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_age = tf.feature_column.numeric_column('HouseAge')\n",
    "av_rooms = tf.feature_column.numeric_column('AveRooms')\n",
    "av_bedroom = tf.feature_column.numeric_column('AveBedrms')\n",
    "population = tf.feature_column.numeric_column('Population')\n",
    "av_occup = tf.feature_column.numeric_column('AveOccup')\n",
    "med_income = tf.feature_column.numeric_column('MedInc')\n",
    "longitude = tf.feature_column.numeric_column('Longitude')\n",
    "latitude = tf.feature_column.numeric_column('Latitude')\n",
    "\n",
    "feat_columns = [house_age, av_rooms, av_bedroom, population, av_occup, med_income, longitude, latitude]\n",
    "feat_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the input function for the estimator object. (play around with batch_size and num_epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train, y=y_train, batch_size=10,num_epochs=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model. Use a DNNRegressor. Play around with the hidden units! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\user\\AppData\\Local\\Temp\\tmpx8xw6weu\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Temp\\\\tmpx8xw6weu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001AA334090B8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNRegressor(hidden_units=[10, 12, 14, 12, 10], feature_columns=feat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** Train the model for ~1,000 steps. (Later come back to this and train it for more and check for improvement) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\user\\AppData\\Local\\Temp\\tmpx8xw6weu\\model.ckpt.\n",
      "INFO:tensorflow:loss = 46.645535, step = 1\n",
      "INFO:tensorflow:global_step/sec: 211.089\n",
      "INFO:tensorflow:loss = 12.168902, step = 101 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.331\n",
      "INFO:tensorflow:loss = 9.421077, step = 201 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.837\n",
      "INFO:tensorflow:loss = 4.837052, step = 301 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.621\n",
      "INFO:tensorflow:loss = 7.211322, step = 401 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.039\n",
      "INFO:tensorflow:loss = 4.1323447, step = 501 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.858\n",
      "INFO:tensorflow:loss = 6.4314957, step = 601 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.571\n",
      "INFO:tensorflow:loss = 5.533518, step = 701 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.698\n",
      "INFO:tensorflow:loss = 2.197783, step = 801 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.167\n",
      "INFO:tensorflow:loss = 5.7995396, step = 901 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.641\n",
      "INFO:tensorflow:loss = 5.352931, step = 1001 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.284\n",
      "INFO:tensorflow:loss = 2.2123795, step = 1101 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.694\n",
      "INFO:tensorflow:loss = 16.212954, step = 1201 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.679\n",
      "INFO:tensorflow:loss = 10.135673, step = 1301 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.763\n",
      "INFO:tensorflow:loss = 11.931221, step = 1401 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.923\n",
      "INFO:tensorflow:loss = 5.335784, step = 1501 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.564\n",
      "INFO:tensorflow:loss = 4.8454776, step = 1601 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.676\n",
      "INFO:tensorflow:loss = 7.38185, step = 1701 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.486\n",
      "INFO:tensorflow:loss = 7.1910834, step = 1801 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.676\n",
      "INFO:tensorflow:loss = 10.973151, step = 1901 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.879\n",
      "INFO:tensorflow:loss = 3.592613, step = 2001 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.472\n",
      "INFO:tensorflow:loss = 6.243657, step = 2101 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.675\n",
      "INFO:tensorflow:loss = 1.2269086, step = 2201 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.643\n",
      "INFO:tensorflow:loss = 3.6747408, step = 2301 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.378\n",
      "INFO:tensorflow:loss = 13.483534, step = 2401 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.903\n",
      "INFO:tensorflow:loss = 4.8909693, step = 2501 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.939\n",
      "INFO:tensorflow:loss = 0.78233826, step = 2601 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.639\n",
      "INFO:tensorflow:loss = 1.572598, step = 2701 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.19\n",
      "INFO:tensorflow:loss = 1.6564893, step = 2801 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.667\n",
      "INFO:tensorflow:loss = 2.3208308, step = 2901 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.865\n",
      "INFO:tensorflow:loss = 2.9348671, step = 3001 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.866\n",
      "INFO:tensorflow:loss = 6.2074122, step = 3101 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.125\n",
      "INFO:tensorflow:loss = 1.4157485, step = 3201 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.806\n",
      "INFO:tensorflow:loss = 2.5043476, step = 3301 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.606\n",
      "INFO:tensorflow:loss = 4.6594954, step = 3401 (0.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.272\n",
      "INFO:tensorflow:loss = 1.981963, step = 3501 (0.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.229\n",
      "INFO:tensorflow:loss = 4.781082, step = 3601 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.151\n",
      "INFO:tensorflow:loss = 3.2252803, step = 3701 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.787\n",
      "INFO:tensorflow:loss = 8.360383, step = 3801 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.696\n",
      "INFO:tensorflow:loss = 3.8106773, step = 3901 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.04\n",
      "INFO:tensorflow:loss = 1.8269398, step = 4001 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.644\n",
      "INFO:tensorflow:loss = 4.334996, step = 4101 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.861\n",
      "INFO:tensorflow:loss = 0.56178474, step = 4201 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.016\n",
      "INFO:tensorflow:loss = 3.5138562, step = 4301 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.531\n",
      "INFO:tensorflow:loss = 2.490045, step = 4401 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.711\n",
      "INFO:tensorflow:loss = 4.6047125, step = 4501 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.057\n",
      "INFO:tensorflow:loss = 3.101699, step = 4601 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.639\n",
      "INFO:tensorflow:loss = 5.685119, step = 4701 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.885\n",
      "INFO:tensorflow:loss = 3.259841, step = 4801 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.964\n",
      "INFO:tensorflow:loss = 5.6930337, step = 4901 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.531\n",
      "INFO:tensorflow:loss = 3.8048844, step = 5001 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.061\n",
      "INFO:tensorflow:loss = 8.104285, step = 5101 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.571\n",
      "INFO:tensorflow:loss = 4.7940707, step = 5201 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.71\n",
      "INFO:tensorflow:loss = 3.9529097, step = 5301 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.284\n",
      "INFO:tensorflow:loss = 2.8053336, step = 5401 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.71\n",
      "INFO:tensorflow:loss = 3.1676488, step = 5501 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.165\n",
      "INFO:tensorflow:loss = 2.9062772, step = 5601 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.299\n",
      "INFO:tensorflow:loss = 10.970813, step = 5701 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.349\n",
      "INFO:tensorflow:loss = 1.7511327, step = 5801 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.049\n",
      "INFO:tensorflow:loss = 12.167228, step = 5901 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.922\n",
      "INFO:tensorflow:loss = 2.141974, step = 6001 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.448\n",
      "INFO:tensorflow:loss = 1.7349942, step = 6101 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.689\n",
      "INFO:tensorflow:loss = 4.6298246, step = 6201 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.283\n",
      "INFO:tensorflow:loss = 4.424688, step = 6301 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.365\n",
      "INFO:tensorflow:loss = 1.6119621, step = 6401 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.285\n",
      "INFO:tensorflow:loss = 5.693258, step = 6501 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.905\n",
      "INFO:tensorflow:loss = 5.3187876, step = 6601 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.569\n",
      "INFO:tensorflow:loss = 1.1091725, step = 6701 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.983\n",
      "INFO:tensorflow:loss = 3.2004561, step = 6801 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.288\n",
      "INFO:tensorflow:loss = 4.90868, step = 6901 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.676\n",
      "INFO:tensorflow:loss = 1.7522982, step = 7001 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.017\n",
      "INFO:tensorflow:loss = 6.642308, step = 7101 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.025\n",
      "INFO:tensorflow:loss = 7.3020873, step = 7201 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.158\n",
      "INFO:tensorflow:loss = 2.7640543, step = 7301 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.53\n",
      "INFO:tensorflow:loss = 2.0761037, step = 7401 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.85\n",
      "INFO:tensorflow:loss = 3.9425542, step = 7501 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.711\n",
      "INFO:tensorflow:loss = 2.7363615, step = 7601 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.059\n",
      "INFO:tensorflow:loss = 1.2137653, step = 7701 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.664\n",
      "INFO:tensorflow:loss = 5.249541, step = 7801 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.942\n",
      "INFO:tensorflow:loss = 1.5666487, step = 7901 (0.464 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.0981843, step = 8001 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.051\n",
      "INFO:tensorflow:loss = 5.3809786, step = 8101 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.245\n",
      "INFO:tensorflow:loss = 5.8871803, step = 8201 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.078\n",
      "INFO:tensorflow:loss = 1.9665177, step = 8301 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.768\n",
      "INFO:tensorflow:loss = 4.180333, step = 8401 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.881\n",
      "INFO:tensorflow:loss = 2.8526218, step = 8501 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.877\n",
      "INFO:tensorflow:loss = 4.229879, step = 8601 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.788\n",
      "INFO:tensorflow:loss = 1.1900156, step = 8701 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.14\n",
      "INFO:tensorflow:loss = 0.72454834, step = 8801 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.206\n",
      "INFO:tensorflow:loss = 1.123506, step = 8901 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.199\n",
      "INFO:tensorflow:loss = 2.219789, step = 9001 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.851\n",
      "INFO:tensorflow:loss = 1.4127239, step = 9101 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.637\n",
      "INFO:tensorflow:loss = 7.084935, step = 9201 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.153\n",
      "INFO:tensorflow:loss = 0.91646045, step = 9301 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.709\n",
      "INFO:tensorflow:loss = 6.6471095, step = 9401 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.733\n",
      "INFO:tensorflow:loss = 4.21044, step = 9501 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.159\n",
      "INFO:tensorflow:loss = 12.440838, step = 9601 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.214\n",
      "INFO:tensorflow:loss = 1.5697474, step = 9701 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.928\n",
      "INFO:tensorflow:loss = 0.93493164, step = 9801 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.812\n",
      "INFO:tensorflow:loss = 3.2027693, step = 9901 (0.325 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into C:\\Users\\user\\AppData\\Local\\Temp\\tmpx8xw6weu\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.0764495.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x1aa33402f60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn = input_func, steps = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_input_func = tf.estimator.inputs.pandas_input_fn(x=X_test, batch_size=20,num_epochs=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\user\\AppData\\Local\\Temp\\tmpx8xw6weu\\model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "pred_model = model.predict(pred_input_func)\n",
    "preds = list(pred_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_y_preds = []\n",
    "for pred in preds:\n",
    "    final_y_preds.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([2.0562935], dtype=float32),\n",
       " array([0.73828584], dtype=float32),\n",
       " array([2.9712858], dtype=float32),\n",
       " array([1.8051349], dtype=float32),\n",
       " array([2.9949076], dtype=float32),\n",
       " array([3.3938513], dtype=float32),\n",
       " array([3.3423793], dtype=float32),\n",
       " array([1.4140904], dtype=float32),\n",
       " array([1.5106106], dtype=float32),\n",
       " array([1.9068263], dtype=float32),\n",
       " array([2.1046596], dtype=float32),\n",
       " array([0.823232], dtype=float32),\n",
       " array([1.0733994], dtype=float32),\n",
       " array([2.800841], dtype=float32),\n",
       " array([1.111978], dtype=float32),\n",
       " array([1.7507142], dtype=float32),\n",
       " array([4.1155095], dtype=float32),\n",
       " array([1.8391138], dtype=float32),\n",
       " array([1.4606333], dtype=float32),\n",
       " array([3.2427826], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_y_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate the RMSE. You should be able to get around 100,000 RMSE (remember that this is in the same units as the label.) Do this manually or use [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6694919797841007"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = math.sqrt(metrics.mean_squared_error(y_test, final_y_preds))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
